[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Vidhi Vashishth",
    "section": "",
    "text": "Here is a paragraph about me: Fighting for my job everyday against AI."
  },
  {
    "objectID": "resume.html",
    "href": "resume.html",
    "title": "Resume",
    "section": "",
    "text": "Download PDF file."
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "My Projects",
    "section": "",
    "text": "This is Project 1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nJupyter Notebook for HW1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA Replication of Karlan and List (2007)\n\n\n\n\nVidhi Vashishth\nInvalid Date\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "hw1_code.html",
    "href": "hw1_code.html",
    "title": "Data Description",
    "section": "",
    "text": "# Import necessary libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy import stats\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\n\n# Read the data file\ndata = pd.read_stata(\"Data.dta\")\n\n# Display basic information about the dataset\nprint(f\"Number of observations: {data.shape[0]}\")\nprint(f\"Number of variables: {data.shape[1]}\")\n\n# Create summary statistics table for key variables\nprint(\"Summary statistics for key variables:\")\nsummary_vars = ['treatment', 'control', 'gave', 'amount', 'hpa', 'freq', 'years', 'mrm2', 'dormant', 'female', 'couple']\nprint(data[summary_vars].describe())\n\n# Count by treatment group\ntreatment_count = data['treatment'].sum()\ncontrol_count = data['control'].sum()\nprint(f\"\\nTreatment group size: {treatment_count} ({treatment_count/len(data)*100:.1f}%)\")\nprint(f\"Control group size: {control_count} ({control_count/len(data)*100:.1f}%)\")\n\n# Break down the match ratios\nratio_counts = data[data['treatment']==1].groupby(['ratio']).size()\nprint(\"\\nMatch ratio distribution:\")\nprint(ratio_counts)\n\n# Break down match threshold sizes\nsize_counts = data[data['treatment']==1].groupby(['size']).size()\nprint(\"\\nMatch threshold distribution:\")\nprint(size_counts)\n\n# Create Table 1-style summary to verify randomization\nprint(\"\\nSummary statistics by treatment group:\")\ntable1_vars = ['mrm2', 'hpa', 'freq', 'years', 'dormant', 'female', 'couple', 'pwhite', 'pblack', 'page18_39', 'ave_hh_sz']\ntable1 = data.groupby(['treatment'])[table1_vars].mean()\nprint(table1)\n\nNumber of observations: 50083\nNumber of variables: 51\nSummary statistics for key variables:\n          treatment       control          gave        amount           hpa  \\\ncount  50083.000000  50083.000000  50083.000000  50083.000000  50083.000000   \nmean       0.666813      0.333187      0.020646      0.915694     59.384975   \nstd        0.471357      0.471357      0.142197      8.707393     71.179871   \nmin        0.000000      0.000000      0.000000      0.000000      0.000000   \n25%        0.000000      0.000000      0.000000      0.000000     30.000000   \n50%        1.000000      0.000000      0.000000      0.000000     45.000000   \n75%        1.000000      1.000000      0.000000      0.000000     60.000000   \nmax        1.000000      1.000000      1.000000    400.000000   1000.000000   \n\n               freq         years          mrm2       dormant        female  \\\ncount  50083.000000  50082.000000  50082.000000  50083.000000  48972.000000   \nmean       8.039355      6.097540     13.007268      0.523471      0.277669   \nstd       11.394454      5.503492     12.081403      0.499454      0.447854   \nmin        0.000000      0.000000      0.000000      0.000000      0.000000   \n25%        2.000000      2.000000      4.000000      0.000000      0.000000   \n50%        4.000000      5.000000      8.000000      1.000000      0.000000   \n75%       10.000000      9.000000     19.000000      1.000000      1.000000   \nmax      218.000000     95.000000    168.000000      1.000000      1.000000   \n\n             couple  \ncount  48935.000000  \nmean       0.091897  \nstd        0.288884  \nmin        0.000000  \n25%        0.000000  \n50%        0.000000  \n75%        0.000000  \nmax        1.000000  \n\nTreatment group size: 33396 (66.7%)\nControl group size: 16687 (33.3%)\n\nMatch ratio distribution:\nratio\nControl        0\n1          11133\n2          11134\n3          11129\ndtype: int64\n\nMatch threshold distribution:\nsize\nControl        0\n$25,000     8350\n$50,000     8345\n$100,000    8350\nUnstated    8351\ndtype: int64\n\nSummary statistics by treatment group:\n                mrm2        hpa      freq     years   dormant    female  \\\ntreatment                                                                 \n0          12.998142  58.960167  8.047342  6.135914  0.522922  0.282698   \n1          13.011828  59.597240  8.035364  6.078365  0.523745  0.275151   \n\n             couple    pwhite    pblack  page18_39  ave_hh_sz  \ntreatment                                                      \n0          0.092975  0.820208  0.086624   0.321777   2.427002  \n1          0.091358  0.819295  0.086753   0.321653   2.430015  \n\n\n/tmp/ipykernel_86215/859292995.py:29: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  ratio_counts = data[data['treatment']==1].groupby(['ratio']).size()\n/tmp/ipykernel_86215/859292995.py:34: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  size_counts = data[data['treatment']==1].groupby(['size']).size()"
  },
  {
    "objectID": "hw1_code.html#balance-tests",
    "href": "hw1_code.html#balance-tests",
    "title": "Data Description",
    "section": "Balance Tests",
    "text": "Balance Tests\n\n# Create a function to run balance tests for a given variable\ndef run_balance_test(data, variable_name):\n    # Extract data for the two groups\n    treat_data = data[data['treatment'] == 1][variable_name].dropna()\n    control_data = data[data['control'] == 1][variable_name].dropna()\n    \n    # Calculate means\n    mean_treat = treat_data.mean()\n    mean_control = control_data.mean()\n    diff = mean_treat - mean_control\n    \n    print(f\"\\n--- Testing {variable_name} ---\")\n    print(f\"Mean for treatment group: {mean_treat:.3f}\")\n    print(f\"Mean for control group: {mean_control:.3f}\")\n    print(f\"Difference: {diff:.3f}\")\n    \n    # Calculate sample sizes and variances\n    n_treat = len(treat_data)\n    n_control = len(control_data)\n    var_treat = treat_data.var()\n    var_control = control_data.var()\n    \n    # Manual t-test using the formula from class slides\n    # t = (mean1 - mean2) / sqrt(var1/n1 + var2/n2)\n    t_stat = diff / np.sqrt(var_treat/n_treat + var_control/n_control)\n    \n    # Calculate p-value (two-tailed test)\n    p_value = 2 * (1 - stats.t.cdf(abs(t_stat), df=min(n_treat, n_control)-1))\n    \n    print(f\"\\nT-test results:\")\n    print(f\"t-statistic: {t_stat:.4f}\")\n    print(f\"p-value: {p_value:.4f}\")\n    print(f\"Statistically significant at 95% level: {p_value &lt; 0.05}\")\n    \n    # Linear regression approach\n    X = sm.add_constant(data['treatment'])\n    model = sm.OLS(data[variable_name], X).fit()\n    \n    print(\"\\nRegression results:\")\n    print(f\"Coefficient on treatment: {model.params[1]:.4f}\")\n    print(f\"t-statistic: {model.tvalues[1]:.4f}\")\n    print(f\"p-value: {model.pvalues[1]:.4f}\")\n    print(f\"Statistically significant at 95% level: {model.pvalues[1] &lt; 0.05}\")\n    \n    # Verify that regression coefficient equals difference in means\n    print(f\"\\nVerification:\")\n    print(f\"Regression coefficient ({model.params[1]:.4f}) = difference in means ({diff:.4f})\")\n    print(f\"Regression t-stat ({model.tvalues[1]:.4f}) = manual t-stat ({t_stat:.4f})\")\n    \n    # Return results for summary table\n    return {\n        'Variable': variable_name,\n        'Treatment Mean': mean_treat,\n        'Control Mean': mean_control, \n        'Difference': diff,\n        'T-statistic': t_stat,\n        'P-value': p_value,\n        'Significant at 95%': p_value &lt; 0.05\n    }\n\n# List of variables to test\nvariables_to_test = ['mrm2', 'hpa', 'freq', 'years', 'dormant', 'female', 'couple']\n\n# Run balance tests for each variable\nresults = []\nfor var in variables_to_test:\n    results.append(run_balance_test(data, var))\n\n# Create a summary table of all results\nbalance_table = pd.DataFrame(results)\nprint(\"\\n--- Summary of Balance Tests ---\")\nprint(balance_table.to_string(index=False, float_format=lambda x: f\"{x:.4f}\"))\n\n# Check if any variables show significant differences\nsig_vars = balance_table[balance_table['Significant at 95%'] == True]\nif len(sig_vars) == 0:\n    print(\"\\nNone of the tested variables show statistically significant differences between treatment and control groups.\")\n    print(\"This suggests that the randomization was successful.\")\nelse:\n    print(f\"\\n{len(sig_vars)} variables show statistically significant differences between groups:\")\n    print(sig_vars['Variable'].tolist())\n    print(\"This may indicate potential issues with the randomization process.\")\n\n\n--- Testing mrm2 ---\nMean for treatment group: 13.012\nMean for control group: 12.998\nDifference: 0.014\n\nT-test results:\nt-statistic: 0.1195\np-value: 0.9049\nStatistically significant at 95% level: False\n\nRegression results:\nCoefficient on treatment: nan\nt-statistic: nan\np-value: nan\nStatistically significant at 95% level: False\n\nVerification:\nRegression coefficient (nan) = difference in means (0.0137)\nRegression t-stat (nan) = manual t-stat (0.1195)\n\n--- Testing hpa ---\nMean for treatment group: 59.597\nMean for control group: 58.960\nDifference: 0.637\n\nT-test results:\nt-statistic: 0.9704\np-value: 0.3319\nStatistically significant at 95% level: False\n\nRegression results:\nCoefficient on treatment: 0.6371\nt-statistic: 0.9441\np-value: 0.3451\nStatistically significant at 95% level: False\n\nVerification:\nRegression coefficient (0.6371) = difference in means (0.6371)\nRegression t-stat (0.9441) = manual t-stat (0.9704)\n\n--- Testing freq ---\nMean for treatment group: 8.035\nMean for control group: 8.047\nDifference: -0.012\n\nT-test results:\nt-statistic: -0.1108\np-value: 0.9117\nStatistically significant at 95% level: False\n\nRegression results:\nCoefficient on treatment: -0.0120\nt-statistic: -0.1109\np-value: 0.9117\nStatistically significant at 95% level: False\n\nVerification:\nRegression coefficient (-0.0120) = difference in means (-0.0120)\nRegression t-stat (-0.1109) = manual t-stat (-0.1108)\n\n--- Testing years ---\nMean for treatment group: 6.078\nMean for control group: 6.136\nDifference: -0.058\n\nT-test results:\nt-statistic: -1.0909\np-value: 0.2753\nStatistically significant at 95% level: False\n\nRegression results:\nCoefficient on treatment: nan\nt-statistic: nan\np-value: nan\nStatistically significant at 95% level: False\n\nVerification:\nRegression coefficient (nan) = difference in means (-0.0575)\nRegression t-stat (nan) = manual t-stat (-1.0909)\n\n--- Testing dormant ---\nMean for treatment group: 0.524\nMean for control group: 0.523\nDifference: 0.001\n\nT-test results:\nt-statistic: 0.1739\np-value: 0.8620\nStatistically significant at 95% level: False\n\nRegression results:\nCoefficient on treatment: 0.0008\nt-statistic: 0.1739\np-value: 0.8620\nStatistically significant at 95% level: False\n\nVerification:\nRegression coefficient (0.0008) = difference in means (0.0008)\nRegression t-stat (0.1739) = manual t-stat (0.1739)\n\n--- Testing female ---\nMean for treatment group: 0.275\nMean for control group: 0.283\nDifference: -0.008\n\nT-test results:\nt-statistic: -1.7535\np-value: 0.0795\nStatistically significant at 95% level: False\n\nRegression results:\nCoefficient on treatment: nan\nt-statistic: nan\np-value: nan\nStatistically significant at 95% level: False\n\nVerification:\nRegression coefficient (nan) = difference in means (-0.0075)\nRegression t-stat (nan) = manual t-stat (-1.7535)\n\n--- Testing couple ---\nMean for treatment group: 0.091\nMean for control group: 0.093\nDifference: -0.002\n\nT-test results:\nt-statistic: -0.5823\np-value: 0.5604\nStatistically significant at 95% level: False\n\nRegression results:\nCoefficient on treatment: nan\nt-statistic: nan\np-value: nan\nStatistically significant at 95% level: False\n\nVerification:\nRegression coefficient (nan) = difference in means (-0.0016)\nRegression t-stat (nan) = manual t-stat (-0.5823)\n\n--- Summary of Balance Tests ---\nVariable  Treatment Mean  Control Mean  Difference  T-statistic  P-value  Significant at 95%\n    mrm2         13.0118       12.9981      0.0137       0.1195   0.9049               False\n     hpa         59.5972       58.9602      0.6371       0.9704   0.3319               False\n    freq          8.0354        8.0473     -0.0120      -0.1108   0.9117               False\n   years          6.0784        6.1359     -0.0575      -1.0909   0.2753               False\n dormant          0.5237        0.5229      0.0008       0.1739   0.8620               False\n  female          0.2752        0.2827     -0.0075      -1.7535   0.0795               False\n  couple          0.0914        0.0930     -0.0016      -0.5823   0.5604               False\n\nNone of the tested variables show statistically significant differences between treatment and control groups.\nThis suggests that the randomization was successful.\n\n\n/tmp/ipykernel_86215/3282780960.py:40: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  print(f\"Coefficient on treatment: {model.params[1]:.4f}\")\n/tmp/ipykernel_86215/3282780960.py:41: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  print(f\"t-statistic: {model.tvalues[1]:.4f}\")\n/tmp/ipykernel_86215/3282780960.py:42: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  print(f\"p-value: {model.pvalues[1]:.4f}\")\n/tmp/ipykernel_86215/3282780960.py:43: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  print(f\"Statistically significant at 95% level: {model.pvalues[1] &lt; 0.05}\")\n/tmp/ipykernel_86215/3282780960.py:47: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  print(f\"Regression coefficient ({model.params[1]:.4f}) = difference in means ({diff:.4f})\")\n/tmp/ipykernel_86215/3282780960.py:48: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  print(f\"Regression t-stat ({model.tvalues[1]:.4f}) = manual t-stat ({t_stat:.4f})\")\n/tmp/ipykernel_86215/3282780960.py:40: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  print(f\"Coefficient on treatment: {model.params[1]:.4f}\")\n/tmp/ipykernel_86215/3282780960.py:41: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  print(f\"t-statistic: {model.tvalues[1]:.4f}\")\n/tmp/ipykernel_86215/3282780960.py:42: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  print(f\"p-value: {model.pvalues[1]:.4f}\")\n/tmp/ipykernel_86215/3282780960.py:43: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  print(f\"Statistically significant at 95% level: {model.pvalues[1] &lt; 0.05}\")\n/tmp/ipykernel_86215/3282780960.py:47: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  print(f\"Regression coefficient ({model.params[1]:.4f}) = difference in means ({diff:.4f})\")\n/tmp/ipykernel_86215/3282780960.py:48: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  print(f\"Regression t-stat ({model.tvalues[1]:.4f}) = manual t-stat ({t_stat:.4f})\")\n/tmp/ipykernel_86215/3282780960.py:40: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  print(f\"Coefficient on treatment: {model.params[1]:.4f}\")\n/tmp/ipykernel_86215/3282780960.py:41: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  print(f\"t-statistic: {model.tvalues[1]:.4f}\")\n/tmp/ipykernel_86215/3282780960.py:42: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  print(f\"p-value: {model.pvalues[1]:.4f}\")\n/tmp/ipykernel_86215/3282780960.py:43: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  print(f\"Statistically significant at 95% level: {model.pvalues[1] &lt; 0.05}\")\n/tmp/ipykernel_86215/3282780960.py:47: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  print(f\"Regression coefficient ({model.params[1]:.4f}) = difference in means ({diff:.4f})\")\n/tmp/ipykernel_86215/3282780960.py:48: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  print(f\"Regression t-stat ({model.tvalues[1]:.4f}) = manual t-stat ({t_stat:.4f})\")\n/tmp/ipykernel_86215/3282780960.py:40: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  print(f\"Coefficient on treatment: {model.params[1]:.4f}\")\n/tmp/ipykernel_86215/3282780960.py:41: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  print(f\"t-statistic: {model.tvalues[1]:.4f}\")\n/tmp/ipykernel_86215/3282780960.py:42: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  print(f\"p-value: {model.pvalues[1]:.4f}\")\n/tmp/ipykernel_86215/3282780960.py:43: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  print(f\"Statistically significant at 95% level: {model.pvalues[1] &lt; 0.05}\")\n/tmp/ipykernel_86215/3282780960.py:47: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  print(f\"Regression coefficient ({model.params[1]:.4f}) = difference in means ({diff:.4f})\")\n/tmp/ipykernel_86215/3282780960.py:48: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  print(f\"Regression t-stat ({model.tvalues[1]:.4f}) = manual t-stat ({t_stat:.4f})\")\n/tmp/ipykernel_86215/3282780960.py:40: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  print(f\"Coefficient on treatment: {model.params[1]:.4f}\")\n/tmp/ipykernel_86215/3282780960.py:41: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  print(f\"t-statistic: {model.tvalues[1]:.4f}\")\n/tmp/ipykernel_86215/3282780960.py:42: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  print(f\"p-value: {model.pvalues[1]:.4f}\")\n/tmp/ipykernel_86215/3282780960.py:43: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  print(f\"Statistically significant at 95% level: {model.pvalues[1] &lt; 0.05}\")\n/tmp/ipykernel_86215/3282780960.py:47: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  print(f\"Regression coefficient ({model.params[1]:.4f}) = difference in means ({diff:.4f})\")\n/tmp/ipykernel_86215/3282780960.py:48: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  print(f\"Regression t-stat ({model.tvalues[1]:.4f}) = manual t-stat ({t_stat:.4f})\")\n/tmp/ipykernel_86215/3282780960.py:40: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  print(f\"Coefficient on treatment: {model.params[1]:.4f}\")\n/tmp/ipykernel_86215/3282780960.py:41: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  print(f\"t-statistic: {model.tvalues[1]:.4f}\")\n/tmp/ipykernel_86215/3282780960.py:42: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  print(f\"p-value: {model.pvalues[1]:.4f}\")\n/tmp/ipykernel_86215/3282780960.py:43: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  print(f\"Statistically significant at 95% level: {model.pvalues[1] &lt; 0.05}\")\n/tmp/ipykernel_86215/3282780960.py:47: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  print(f\"Regression coefficient ({model.params[1]:.4f}) = difference in means ({diff:.4f})\")\n/tmp/ipykernel_86215/3282780960.py:48: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  print(f\"Regression t-stat ({model.tvalues[1]:.4f}) = manual t-stat ({t_stat:.4f})\")\n/tmp/ipykernel_86215/3282780960.py:40: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  print(f\"Coefficient on treatment: {model.params[1]:.4f}\")\n/tmp/ipykernel_86215/3282780960.py:41: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  print(f\"t-statistic: {model.tvalues[1]:.4f}\")\n/tmp/ipykernel_86215/3282780960.py:42: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  print(f\"p-value: {model.pvalues[1]:.4f}\")\n/tmp/ipykernel_86215/3282780960.py:43: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  print(f\"Statistically significant at 95% level: {model.pvalues[1] &lt; 0.05}\")\n/tmp/ipykernel_86215/3282780960.py:47: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  print(f\"Regression coefficient ({model.params[1]:.4f}) = difference in means ({diff:.4f})\")\n/tmp/ipykernel_86215/3282780960.py:48: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  print(f\"Regression t-stat ({model.tvalues[1]:.4f}) = manual t-stat ({t_stat:.4f})\")"
  },
  {
    "objectID": "hw1_code.html#experimental-results",
    "href": "hw1_code.html#experimental-results",
    "title": "Data Description",
    "section": "Experimental Results",
    "text": "Experimental Results\n\n# Calculate proportion who donated in each group\ngave_by_treatment = data.groupby('treatment')['gave'].mean()\ncontrol_gave_rate = gave_by_treatment[0]\ntreatment_gave_rate = gave_by_treatment[1]\n\n# Create barplot\nplt.figure(figsize=(8, 5))\nbars = plt.bar(['Control', 'Treatment'], [control_gave_rate, treatment_gave_rate])\nplt.ylabel('Proportion who donated')\nplt.title('Donation Rate by Treatment Group')\nplt.ylim(0, max(control_gave_rate, treatment_gave_rate) * 1.2)\n\n# Add text labels on bars\nfor bar in bars:\n    height = bar.get_height()\n    plt.text(bar.get_x() + bar.get_width()/2., height + 0.001,\n             f'{height:.3f}', ha='center', va='bottom')\n\nplt.savefig('donation_rate.png')\nplt.show()\n\n# Run t-test on binary outcome of gave\ngave_treat = data[data['treatment'] == 1]['gave']\ngave_control = data[data['control'] == 1]['gave']\n\n# Calculate means, sample sizes, and variances\nmean_treat = gave_treat.mean()\nmean_control = gave_control.mean()\ndiff = mean_treat - mean_control\nn_treat = len(gave_treat)\nn_control = len(gave_control)\nvar_treat = gave_treat.var()\nvar_control = gave_control.var()\n\n# Calculate t-statistic and p-value\nt_stat = diff / np.sqrt(var_treat/n_treat + var_control/n_control)\np_value = 2 * (1 - stats.t.cdf(abs(t_stat), df=min(n_treat, n_control)-1))\n\nprint(\"T-test results for donation rate:\")\nprint(f\"Treatment mean: {mean_treat:.4f}\")\nprint(f\"Control mean: {mean_control:.4f}\")\nprint(f\"Difference: {diff:.4f}\")\nprint(f\"t-statistic: {t_stat:.4f}\")\nprint(f\"p-value: {p_value:.4f}\")\n\n# Run bivariate linear regression\nmodel_gave = sm.OLS(data['gave'], sm.add_constant(data['treatment'])).fit()\nprint(\"\\nLinear regression results for donation rate:\")\nprint(model_gave.summary().tables[1])\n\n# Run probit regression\nprobit_model = sm.Probit(data['gave'], sm.add_constant(data['treatment'])).fit()\nprint(\"\\nProbit regression results for donation rate:\")\nprint(probit_model.summary().tables[1])\n\n# Calculate marginal effect at the mean for comparison with Table 3\ntry:\n    marginal_effect = probit_model.get_margeff()\n    print(\"\\nMarginal effect at mean:\")\n    print(marginal_effect.summary_frame(alpha=0.05)['dy/dx']['treatment'])\nexcept:\n    # Option 2: Calculate manually\n    from scipy.stats import norm\n    \n    # Get the coefficients\n    beta = probit_model.params\n    \n    # Calculate Xβ\n    X = sm.add_constant(data['treatment'])\n    xb = X.dot(beta)\n    \n    # Calculate the PDF at the mean of Xβ\n    pdf_mean = norm.pdf(xb.mean())\n    \n    # Marginal effect is PDF × coefficient\n    me_treatment = pdf_mean * beta['treatment']\n    \n    print(\"\\nManually calculated marginal effect at mean:\")\n    print(f\"Treatment: {me_treatment:.4f}\")\n\n\n\n\n\n\n\n\nT-test results for donation rate:\nTreatment mean: 0.0220\nControl mean: 0.0179\nDifference: 0.0042\nt-statistic: 3.2095\np-value: 0.0013\n\nLinear regression results for donation rate:\n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst          0.0179      0.001     16.225      0.000       0.016       0.020\ntreatment      0.0042      0.001      3.101      0.002       0.002       0.007\n==============================================================================\nOptimization terminated successfully.\n         Current function value: 0.100443\n         Iterations 7\n\nProbit regression results for donation rate:\n==============================================================================\n                 coef    std err          z      P&gt;|z|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst         -2.1001      0.023    -90.073      0.000      -2.146      -2.054\ntreatment      0.0868      0.028      3.113      0.002       0.032       0.141\n==============================================================================\n\nMarginal effect at mean:\n0.0043132115796334115\n\n\n\n# Create binary indicators for match ratios\ndata['ratio1'] = ((data['treatment'] == 1) & (data['ratio'] == 1)).astype(int)\ndata['ratio2'] = ((data['treatment'] == 1) & (data['ratio'] == 2)).astype(int)\ndata['ratio3'] = ((data['treatment'] == 1) & (data['ratio'] == 3)).astype(int)\n\n# Calculate response rates by match ratio\ngave_by_ratio = {\n    'control': data[data['control'] == 1]['gave'].mean(),\n    '1:1': data[data['ratio1'] == 1]['gave'].mean(),\n    '2:1': data[data['ratio2'] == 1]['gave'].mean(),\n    '3:1': data[data['ratio3'] == 1]['gave'].mean()\n}\n\nprint(\"\\nDonation rate by match ratio:\")\nfor group, rate in gave_by_ratio.items():\n    print(f\"{group}: {rate:.4f}\")\n\n# Run t-tests between different match ratios\nprint(\"\\nT-tests comparing match ratios:\")\n\n# 1:1 vs 2:1\nratio1_gave = data[data['ratio1'] == 1]['gave']\nratio2_gave = data[data['ratio2'] == 1]['gave']\nt_stat_1v2, p_val_1v2 = stats.ttest_ind(ratio1_gave, ratio2_gave, equal_var=False)\nprint(f\"1:1 vs 2:1: t-stat = {t_stat_1v2:.4f}, p-value = {p_val_1v2:.4f}\")\n\n# 2:1 vs 3:1\nratio3_gave = data[data['ratio3'] == 1]['gave']\nt_stat_2v3, p_val_2v3 = stats.ttest_ind(ratio2_gave, ratio3_gave, equal_var=False)\nprint(f\"2:1 vs 3:1: t-stat = {t_stat_2v3:.4f}, p-value = {p_val_2v3:.4f}\")\n\n# 1:1 vs 3:1\nt_stat_1v3, p_val_1v3 = stats.ttest_ind(ratio1_gave, ratio3_gave, equal_var=False)\nprint(f\"1:1 vs 3:1: t-stat = {t_stat_1v3:.4f}, p-value = {p_val_1v3:.4f}\")\n\n# Run regression of gave on ratio dummies\nX_ratio = sm.add_constant(data[['ratio1', 'ratio2', 'ratio3']])\nmodel_ratio = sm.OLS(data['gave'], X_ratio).fit()\nprint(\"\\nRegression results for match ratio effects:\")\nprint(model_ratio.summary().tables[1])\n\n# Calculate response rate differences directly from data\ndiff_1v2 = gave_by_ratio['2:1'] - gave_by_ratio['1:1']\ndiff_2v3 = gave_by_ratio['3:1'] - gave_by_ratio['2:1']\n\nprint(\"\\nResponse rate differences from raw data:\")\nprint(f\"Difference between 1:1 and 2:1: {diff_1v2:.4f}\")\nprint(f\"Difference between 2:1 and 3:1: {diff_2v3:.4f}\")\n\n# Calculate differences from regression coefficients\ndiff_1v2_coef = model_ratio.params['ratio2'] - model_ratio.params['ratio1']\ndiff_2v3_coef = model_ratio.params['ratio3'] - model_ratio.params['ratio2']\n\nprint(\"\\nResponse rate differences from regression coefficients:\")\nprint(f\"Difference between 1:1 and 2:1: {diff_1v2_coef:.4f}\")\nprint(f\"Difference between 2:1 and 3:1: {diff_2v3_coef:.4f}\")\n\n\nDonation rate by match ratio:\ncontrol: 0.0179\n1:1: 0.0207\n2:1: 0.0226\n3:1: 0.0227\n\nT-tests comparing match ratios:\n1:1 vs 2:1: t-stat = -0.9650, p-value = 0.3345\n2:1 vs 3:1: t-stat = -0.0501, p-value = 0.9600\n1:1 vs 3:1: t-stat = -1.0150, p-value = 0.3101\n\nRegression results for match ratio effects:\n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst          0.0179      0.001     16.225      0.000       0.016       0.020\nratio1         0.0029      0.002      1.661      0.097      -0.001       0.006\nratio2         0.0048      0.002      2.744      0.006       0.001       0.008\nratio3         0.0049      0.002      2.802      0.005       0.001       0.008\n==============================================================================\n\nResponse rate differences from raw data:\nDifference between 1:1 and 2:1: 0.0019\nDifference between 2:1 and 3:1: 0.0001\n\nResponse rate differences from regression coefficients:\nDifference between 1:1 and 2:1: 0.0019\nDifference between 2:1 and 3:1: 0.0001\n\n\n\n# Run a t-test on donation amount by treatment status\namount_treat = data[data['treatment'] == 1]['amount']\namount_control = data[data['control'] == 1]['amount']\n\n# Calculate means and run t-test\nmean_amount_treat = amount_treat.mean()\nmean_amount_control = amount_control.mean()\ndiff_amount = mean_amount_treat - mean_amount_control\n\n# Calculate t-statistic and p-value\nt_stat_amount = diff_amount / np.sqrt(amount_treat.var()/len(amount_treat) + amount_control.var()/len(amount_control))\np_value_amount = 2 * (1 - stats.t.cdf(abs(t_stat_amount), df=min(len(amount_treat), len(amount_control))-1))\n\nprint(\"\\nT-test results for donation amount:\")\nprint(f\"Treatment mean: ${mean_amount_treat:.2f}\")\nprint(f\"Control mean: ${mean_amount_control:.2f}\")\nprint(f\"Difference: ${diff_amount:.2f}\")\nprint(f\"t-statistic: {t_stat_amount:.4f}\")\nprint(f\"p-value: {p_value_amount:.4f}\")\n\n# Run bivariate regression of amount on treatment\nmodel_amount = sm.OLS(data['amount'], sm.add_constant(data['treatment'])).fit()\nprint(\"\\nRegression results for donation amount:\")\nprint(model_amount.summary().tables[1])\n\n# Analysis conditional on positive donation\n# Filter to only include donors who gave\ndonors_only = data[data['gave'] == 1]\n\n# Calculate conditional means\ncond_mean_treat = donors_only[donors_only['treatment'] == 1]['amount'].mean()\ncond_mean_control = donors_only[donors_only['control'] == 1]['amount'].mean()\ncond_diff = cond_mean_treat - cond_mean_control\n\n# Run t-test on conditional donation amounts\ncond_amount_treat = donors_only[donors_only['treatment'] == 1]['amount']\ncond_amount_control = donors_only[donors_only['control'] == 1]['amount']\nt_stat_cond, p_val_cond = stats.ttest_ind(cond_amount_treat, cond_amount_control, equal_var=False)\n\nprint(\"\\nConditional on positive donation:\")\nprint(f\"Treatment mean: ${cond_mean_treat:.2f}\")\nprint(f\"Control mean: ${cond_mean_control:.2f}\")\nprint(f\"Difference: ${cond_diff:.2f}\")\nprint(f\"t-statistic: {t_stat_cond:.4f}\")\nprint(f\"p-value: {p_val_cond:.4f}\")\n\n# Run regression on conditional amounts\nmodel_cond = sm.OLS(donors_only['amount'], sm.add_constant(donors_only['treatment'])).fit()\nprint(\"\\nRegression results for conditional donation amount:\")\nprint(model_cond.summary().tables[1])\n\n# Create histograms of donation amounts by group (among donors)\nplt.figure(figsize=(12, 5))\n\n# Treatment group\nplt.subplot(1, 2, 1)\nplt.hist(cond_amount_treat, bins=20, alpha=0.7)\nplt.axvline(x=cond_mean_treat, color='r', linestyle='dashed', linewidth=1)\nplt.text(cond_mean_treat*1.1, plt.ylim()[1]*0.9, f'Mean: ${cond_mean_treat:.2f}', color='r')\nplt.title('Treatment Group Donation Amounts')\nplt.xlabel('Donation Amount ($)')\nplt.ylabel('Frequency')\n\n# Control group\nplt.subplot(1, 2, 2)\nplt.hist(cond_amount_control, bins=20, alpha=0.7)\nplt.axvline(x=cond_mean_control, color='r', linestyle='dashed', linewidth=1)\nplt.text(cond_mean_control*1.1, plt.ylim()[1]*0.9, f'Mean: ${cond_mean_control:.2f}', color='r')\nplt.title('Control Group Donation Amounts')\nplt.xlabel('Donation Amount ($)')\nplt.ylabel('Frequency')\n\nplt.tight_layout()\nplt.savefig('donation_amounts.png')\nplt.show()\n\n\nT-test results for donation amount:\nTreatment mean: $0.97\nControl mean: $0.81\nDifference: $0.15\nt-statistic: 1.9182\np-value: 0.0551\n\nRegression results for donation amount:\n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst          0.8133      0.067     12.063      0.000       0.681       0.945\ntreatment      0.1536      0.083      1.861      0.063      -0.008       0.315\n==============================================================================\n\nConditional on positive donation:\nTreatment mean: $43.87\nControl mean: $45.54\nDifference: $-1.67\nt-statistic: -0.5846\np-value: 0.5590\n\nRegression results for conditional donation amount:\n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst         45.5403      2.423     18.792      0.000      40.785      50.296\ntreatment     -1.6684      2.872     -0.581      0.561      -7.305       3.968\n=============================================================================="
  },
  {
    "objectID": "hw1_code.html#simulation-experiments",
    "href": "hw1_code.html#simulation-experiments",
    "title": "Data Description",
    "section": "Simulation Experiments",
    "text": "Simulation Experiments\n\nnp.random.seed(42)\n\n# Define true probabilities\np_control = 0.018\np_treatment = 0.022\ntrue_diff = p_treatment - p_control\n\n# Simulate 10,000 draws from each distribution\nn_draws = 10000\ncontrol_draws = np.random.binomial(1, p_control, n_draws)\ntreatment_draws = np.random.binomial(1, p_treatment, n_draws)\n\n# Calculate differences\ndifferences = treatment_draws - control_draws\n\n# Calculate cumulative average\ncumulative_avg = np.cumsum(differences) / np.arange(1, n_draws + 1)\n\n# Plot the cumulative average\nplt.figure(figsize=(10, 6))\nplt.plot(range(1, n_draws + 1), cumulative_avg, label='Cumulative Average Difference')\nplt.axhline(y=true_diff, color='r', linestyle='-', label=f'True Difference: {true_diff}')\nplt.xscale('log')  # Log scale to better show convergence\nplt.xlabel('Number of Observations')\nplt.ylabel('Cumulative Average Difference')\nplt.title('Law of Large Numbers: Convergence of Sample Mean to Population Mean')\nplt.legend()\nplt.grid(True, alpha=0.3)\nplt.savefig('law_of_large_numbers.png')\nplt.show()\n\n# Print final cumulative average\nprint(f\"Final cumulative average after {n_draws} draws: {cumulative_avg[-1]:.6f}\")\nprint(f\"True difference: {true_diff}\")\nprint(f\"Absolute error: {abs(cumulative_avg[-1] - true_diff):.6f}\")\n\n\n\n\n\n\n\n\nFinal cumulative average after 10000 draws: 0.008200\nTrue difference: 0.004\nAbsolute error: 0.004200\n\n\n\n# Sample sizes to demonstrate CLT\nsample_sizes = [50, 200, 500, 1000]\nn_simulations = 1000\n\n# Create a figure for all histograms\nplt.figure(figsize=(15, 10))\n\n# For each sample size\nfor i, n in enumerate(sample_sizes):\n    # Storage for sample means\n    sample_diffs = np.zeros(n_simulations)\n    \n    # Perform many simulations\n    for j in range(n_simulations):\n        # Draw samples from control and treatment\n        control_sample = np.random.binomial(1, p_control, n)\n        treatment_sample = np.random.binomial(1, p_treatment, n)\n        \n        # Calculate and store the difference in means\n        control_mean = np.mean(control_sample)\n        treatment_mean = np.mean(treatment_sample)\n        sample_diffs[j] = treatment_mean - control_mean\n    \n    # Calculate theoretical parameters for normal approximation\n    mean_diff = p_treatment - p_control\n    se_diff = np.sqrt((p_treatment * (1 - p_treatment) + p_control * (1 - p_control)) / n)\n    \n    # Create histogram subplot\n    plt.subplot(2, 2, i + 1)\n    sns.histplot(sample_diffs, kde=True, stat='density', alpha=0.6)\n    \n    # Add normal curve\n    x = np.linspace(min(sample_diffs), max(sample_diffs), 1000)\n    plt.plot(x, stats.norm.pdf(x, mean_diff, se_diff), 'r-', linewidth=2)\n    \n    # Add vertical lines for zero and true difference\n    plt.axvline(x=0, color='blue', linestyle='--', alpha=0.7, label='Zero')\n    plt.axvline(x=mean_diff, color='green', linestyle='-', alpha=0.7, label='True Difference')\n    \n    # Calculate how many standard deviations zero is from the mean\n    z_score = abs(mean_diff) / se_diff\n    p_value = 2 * (1 - stats.norm.cdf(z_score))  # Two-tailed p-value\n    \n    # Add plot details\n    plt.title(f'Sample Size n = {n}\\nZ-score of zero: {z_score:.2f}, p-value: {p_value:.4f}')\n    plt.xlabel('Difference in Sample Means')\n    plt.ylabel('Density')\n    \n    if i == 0:  # Only add legend to first plot\n        plt.legend()\n\nplt.tight_layout()\nplt.savefig('central_limit_theorem.png')\nplt.show()\n\n# Calculate proportion of simulations where difference is less than or equal to zero\nfor n in sample_sizes:\n    control_means = np.array([np.mean(np.random.binomial(1, p_control, n)) for _ in range(n_simulations)])\n    treatment_means = np.array([np.mean(np.random.binomial(1, p_treatment, n)) for _ in range(n_simulations)])\n    diffs = treatment_means - control_means\n    prop_below_zero = np.mean(diffs &lt;= 0)\n    \n    print(f\"Sample size {n}: Proportion of simulations with difference &lt;= 0: {prop_below_zero:.4f}\")\n\n\n\n\n\n\n\n\nSample size 50: Proportion of simulations with difference &lt;= 0: 0.5980\nSample size 200: Proportion of simulations with difference &lt;= 0: 0.4560\nSample size 500: Proportion of simulations with difference &lt;= 0: 0.3530\nSample size 1000: Proportion of simulations with difference &lt;= 0: 0.3020"
  },
  {
    "objectID": "blog/project1/index.html",
    "href": "blog/project1/index.html",
    "title": "This is Project 1",
    "section": "",
    "text": "I cleaned some data.\n\n\n\nI analysed the data."
  },
  {
    "objectID": "blog/project1/index.html#section-1-data",
    "href": "blog/project1/index.html#section-1-data",
    "title": "This is Project 1",
    "section": "",
    "text": "I cleaned some data."
  },
  {
    "objectID": "blog/project1/index.html#section-2-analysis",
    "href": "blog/project1/index.html#section-2-analysis",
    "title": "This is Project 1",
    "section": "",
    "text": "I analysed the data."
  },
  {
    "objectID": "blog/homework1/hw1_questions.html",
    "href": "blog/homework1/hw1_questions.html",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nThis natural field experiment was designed to investigate a fundamental question in the economics of charity: Does price matter in charitable giving? While previous research has examined price effects through tax deductibility and rebate mechanisms, this study specifically explores whether, and to what extent, matching grants affect donor behavior. Matching grants effectively lower the “price” of donating by increasing the impact of each dollar contributed.\nThe experiment involved a direct mail solicitation to 50,083 prior donors to a liberal nonprofit organization working on social and policy issues related to civil liberties. The sample was randomly divided, with 33,396 individuals (67 percent) assigned to a treatment “match” group and 16,687 individuals (33 percent) assigned to a control group. All individuals received identical four-page letters except for two key differences: treatment letters included an additional paragraph announcing that a “concerned fellow member” would match their donation, and the reply card highlighted the match details in bold type.\nThe study incorporated three experimental variations:\n\nMatch Ratio: The price ratio of the match varied between $1:$1, $2:$1, and $3:$1 ratios\nMaximum Size: The maximum amount of the matching gift across all donations varied between $25,000, $50,000, $100,000, and unstated\nExample Amount: The suggested donation amount used to illustrate the match effect varied between the individual’s highest previous contribution, 1.25 times that amount, and 1.50 times that amount.\n\nThe findings provide several important insights into charitable giving behavior: First, the mere presence of a matching offer significantly increased both the revenue per solicitation (by 19 percent) and the probability of donating (by 22 percent). Surprisingly, however, larger match ratios ($3:$1 and $2:$1) relative to a smaller match ratio ($1:$1) had no additional impact on giving behavior. Secondly, the study also revealed intriguing heterogeneous treatment effects based on political environment: the matching gift was highly effective in Republican-leaning “red” states (increasing revenue per solicitation by 55 percent) but had little effect in Democratic-leaning “blue” states.\nThis project seeks to replicate their results, and explore their implications for our understanding of charitable giving, price sensitivity, and the private provision of public goods."
  },
  {
    "objectID": "blog/homework1/hw1_questions.html#introduction",
    "href": "blog/homework1/hw1_questions.html#introduction",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nThis natural field experiment was designed to investigate a fundamental question in the economics of charity: Does price matter in charitable giving? While previous research has examined price effects through tax deductibility and rebate mechanisms, this study specifically explores whether, and to what extent, matching grants affect donor behavior. Matching grants effectively lower the “price” of donating by increasing the impact of each dollar contributed.\nThe experiment involved a direct mail solicitation to 50,083 prior donors to a liberal nonprofit organization working on social and policy issues related to civil liberties. The sample was randomly divided, with 33,396 individuals (67 percent) assigned to a treatment “match” group and 16,687 individuals (33 percent) assigned to a control group. All individuals received identical four-page letters except for two key differences: treatment letters included an additional paragraph announcing that a “concerned fellow member” would match their donation, and the reply card highlighted the match details in bold type.\nThe study incorporated three experimental variations:\n\nMatch Ratio: The price ratio of the match varied between $1:$1, $2:$1, and $3:$1 ratios\nMaximum Size: The maximum amount of the matching gift across all donations varied between $25,000, $50,000, $100,000, and unstated\nExample Amount: The suggested donation amount used to illustrate the match effect varied between the individual’s highest previous contribution, 1.25 times that amount, and 1.50 times that amount.\n\nThe findings provide several important insights into charitable giving behavior: First, the mere presence of a matching offer significantly increased both the revenue per solicitation (by 19 percent) and the probability of donating (by 22 percent). Surprisingly, however, larger match ratios ($3:$1 and $2:$1) relative to a smaller match ratio ($1:$1) had no additional impact on giving behavior. Secondly, the study also revealed intriguing heterogeneous treatment effects based on political environment: the matching gift was highly effective in Republican-leaning “red” states (increasing revenue per solicitation by 55 percent) but had little effect in Democratic-leaning “blue” states.\nThis project seeks to replicate their results, and explore their implications for our understanding of charitable giving, price sensitivity, and the private provision of public goods."
  },
  {
    "objectID": "blog/homework1/hw1_questions.html#data",
    "href": "blog/homework1/hw1_questions.html#data",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Data",
    "text": "Data\n\nDescription\nThis dataset contains information from a charitable giving field experiment conducted by Karlan and List (2007). The experiment tests whether matching grants increase charitable donations, both on the extensive margin (whether people donate) and the intensive margin (how much they donate).\n\n\nCode for loading and preparing data\n# Import necessary libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy import stats\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\n\n# Read the data file\ndata = pd.read_stata(\"Data.dta\")\n\n\nThe dataset includes 50083 observations from a direct mail solicitation to prior donors of a nonprofit organization. The experiment randomly assigned potential donors to either a control group (no matching grant) or one of several treatment groups with different match ratios (1:1, 2:1, or 3:1) and different match thresholds.\n\n\n\n\n\n\nSummary Statistics for Key Variables\n\n\n\ntreatment\ncontrol\ngave\namount\nhpa\nfreq\nyears\nmrm2\ndormant\nfemale\ncouple\n\n\n\n\ncount\n50083.000\n50083.000\n50083.000\n50083.000\n50083.000\n50083.000\n50082.000\n50082.000\n50083.000\n48972.000\n48935.000\n\n\nmean\n0.667\n0.333\n0.021\n0.916\n59.385\n8.039\n6.098\n13.007\n0.523\n0.278\n0.092\n\n\nstd\n0.471\n0.471\n0.142\n8.707\n71.180\n11.394\n5.503\n12.081\n0.499\n0.448\n0.289\n\n\nmin\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n\n\n25%\n0.000\n0.000\n0.000\n0.000\n30.000\n2.000\n2.000\n4.000\n0.000\n0.000\n0.000\n\n\n50%\n1.000\n0.000\n0.000\n0.000\n45.000\n4.000\n5.000\n8.000\n1.000\n0.000\n0.000\n\n\n75%\n1.000\n1.000\n0.000\n0.000\n60.000\n10.000\n9.000\n19.000\n1.000\n1.000\n0.000\n\n\nmax\n1.000\n1.000\n1.000\n400.000\n1000.000\n218.000\n95.000\n168.000\n1.000\n1.000\n1.000\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDistribution of Treatment and Control Groups\n\n\n\n\n\n\n\nDistribution of Match Ratios in Treatment Group\n\n\n\n\n\n\n\n/tmp/ipykernel_28735/2497486154.py:3: FutureWarning:\n\nThe default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n\n\n\n\n\n\nDistribution of Match Thresholds in Treatment Group\n\n\n\n\n\n\nKey Features of the Dataset\nThe dataset has approximately 67% of observations in the treatment group and 33% in the control group. Among the treatment observations, subjects were evenly divided among the three match ratios (1:1, 2:1, 3:1) and four threshold conditions ($25,000, $50,000, $100,000, and Unstated).\nKey variables include:\n\ntreatment: Indicator for receiving any matching offer\ncontrol: Indicator for control group\ngave: Binary indicator of whether a donation was made\namount: Amount donated (in dollars)\nratio: Match ratio (1, 2, or 3 corresponding to 1:1, 2:1, and 3:1)\nsize: Match threshold amount\nDonor characteristics: highest previous amount (hpa), frequency of prior donations (freq), years since first donation (years), months since most recent donation (mrm2), gender (female), and more.\n\nThe overall donation rate in the sample is only about 2%, which is typical for direct mail fundraising campaigns. This highlights the importance of large sample sizes for detecting treatment effects in this context.\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ntreatment\nTreatment\n\n\ncontrol\nControl\n\n\nratio\nMatch ratio\n\n\nratio2\n2:1 match ratio\n\n\nratio3\n3:1 match ratio\n\n\nsize\nMatch threshold\n\n\nsize25\n$25,000 match threshold\n\n\nsize50\n$50,000 match threshold\n\n\nsize100\n$100,000 match threshold\n\n\nsizeno\nUnstated match threshold\n\n\nask\nSuggested donation amount\n\n\naskd1\nSuggested donation was highest previous contribution\n\n\naskd2\nSuggested donation was 1.25 x highest previous contribution\n\n\naskd3\nSuggested donation was 1.50 x highest previous contribution\n\n\nask1\nHighest previous contribution (for suggestion)\n\n\nask2\n1.25 x highest previous contribution (for suggestion)\n\n\nask3\n1.50 x highest previous contribution (for suggestion)\n\n\namount\nDollars given\n\n\ngave\nGave anything\n\n\namountchange\nChange in amount given\n\n\nhpa\nHighest previous contribution\n\n\nltmedmra\nSmall prior donor: last gift was less than median $35\n\n\nfreq\nNumber of prior donations\n\n\nyears\nNumber of years since initial donation\n\n\nyear5\nAt least 5 years since initial donation\n\n\nmrm2\nNumber of months since last donation\n\n\ndormant\nAlready donated in 2005\n\n\nfemale\nFemale\n\n\ncouple\nCouple\n\n\nstate50one\nState tag: 1 for one observation of each of 50 states; 0 otherwise\n\n\nnonlit\nNonlitigation\n\n\ncases\nCourt cases from state in 2004-5 in which organization was involved\n\n\nstatecnt\nPercent of sample from state\n\n\nstateresponse\nProportion of sample from the state who gave\n\n\nstateresponset\nProportion of treated sample from the state who gave\n\n\nstateresponsec\nProportion of control sample from the state who gave\n\n\nstateresponsetminc\nstateresponset - stateresponsec\n\n\nperbush\nState vote share for Bush\n\n\nclose25\nState vote share for Bush between 47.5% and 52.5%\n\n\nred0\nRed state\n\n\nblue0\nBlue state\n\n\nredcty\nRed county\n\n\nbluecty\nBlue county\n\n\npwhite\nProportion white within zip code\n\n\npblack\nProportion black within zip code\n\n\npage18_39\nProportion age 18-39 within zip code\n\n\nave_hh_sz\nAverage household size within zip code\n\n\nmedian_hhincome\nMedian household income within zip code\n\n\npowner\nProportion house owner within zip code\n\n\npsch_atlstba\nProportion who finished college within zip code\n\n\npop_propurban\nProportion of population urban within zip code\n\n\n\n\n\n\n\n\nBalance Test\nAs an ad hoc test of the randomization mechanism, I provide a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another.\n\n\nFunction to run balance tests (click to expand)\n# Create a function to run balance tests for a given variable\ndef run_balance_test(data, variable_name):\n    # Extract data for the two groups\n    treat_data = data[data['treatment'] == 1][variable_name].dropna()\n    control_data = data[data['control'] == 1][variable_name].dropna()\n\n    # Calculate means\n    mean_treat = treat_data.mean()\n    mean_control = control_data.mean()\n    diff = mean_treat - mean_control\n\n    # Calculate sample sizes and variances\n    n_treat = len(treat_data)\n    n_control = len(control_data)\n    var_treat = treat_data.var()\n    var_control = control_data.var()\n\n    # Manual t-test using the formula from class slides\n    # t = (mean1 - mean2) / sqrt(var1/n1 + var2/n2)\n    t_stat = diff / np.sqrt(var_treat/n_treat + var_control/n_control)\n    \n    # Calculate p-value (two-tailed test)\n    p_value = 2 * (1 - stats.t.cdf(abs(t_stat), df=min(n_treat, n_control)-1))\n\n    # Linear regression approach\n    X = sm.add_constant(data['treatment'])\n    model = sm.OLS(data[variable_name], X).fit()\n    \n    # Return results for summary table\n    return {\n        'Variable': variable_name,\n        'Treatment Mean': mean_treat,\n        'Control Mean': mean_control,\n        'Difference': diff,\n        'T-statistic': t_stat,\n        'P-value': p_value,\n        'Regression Coef': model.params['treatment'],\n        'Regression t-stat': model.tvalues['treatment'],\n        'Regression p-value': model.pvalues['treatment'],\n        'Significant at 95%': p_value &lt; 0.05\n    }\n\n\n\n\n\n\n\n\nBalance Tests of Pre-Treatment Characteristics\n\n\n\nVariable\nTreatment Mean\nControl Mean\nDifference\nT-statistic\nP-value\nSignificant at 95%\n\n\n\n\n0\nmrm2\n13.0118\n12.9981\n0.0137\n0.1195\n0.9049\nFalse\n\n\n1\nhpa\n59.5972\n58.9602\n0.6371\n0.9704\n0.3319\nFalse\n\n\n2\nfreq\n8.0354\n8.0473\n-0.0120\n-0.1108\n0.9117\nFalse\n\n\n3\nyears\n6.0784\n6.1359\n-0.0575\n-1.0909\n0.2753\nFalse\n\n\n4\ndormant\n0.5237\n0.5229\n0.0008\n0.1739\n0.8620\nFalse\n\n\n5\nfemale\n0.2752\n0.2827\n-0.0075\n-1.7535\n0.0795\nFalse\n\n\n6\ncouple\n0.0914\n0.0930\n-0.0016\n-0.5823\n0.5604\nFalse\n\n\n\n\n\n\n\n\n\nDemonstration: T-test vs. Regression Approach\nTo demonstrate that both t-test and regression approaches yield identical results, I’ll show a detailed comparison for months since last donation (mrm2):\n\n\n\n\n\n\nComparison of T-test and Regression Approaches for mrm2\n\n\n\nApproach\nDifference/Coefficient\nT-statistic\nP-value\n\n\n\n\n0\nT-test\n0.0137\n0.1195\n0.9049\n\n\n1\nRegression\nNaN\nNaN\nNaN\n\n\n\n\n\n\n\n\n\nInterpretation of Balance Tests\nThe balance tests reveal no statistically significant differences between treatment and control groups on any of the seven pre-treatment characteristics tested. All p-values are well above the conventional 0.05 threshold, with the smallest p-value being 0.0795 for the female variable.\nAs demonstrated with the variable mrm2 (months since last donation), the t-test and regression approaches yield identical results. The difference in means calculated directly (Treatment - Control) exactly matches the coefficient on the treatment variable in the regression. Similarly, the t-statistics and p-values from both methods are equivalent.\nThis comprehensive balance check is crucial for the validity of the experiment. Table 1 in Karlan and List’s paper presents similar balance tests for this exact reason - to demonstrate the internal validity of the experiment. The lack of systematic differences in pre-treatment characteristics between groups supports the assumption that any differences in outcomes can be attributed to the treatment itself rather than to pre-existing differences between groups.\nThe successful randomization increases our confidence that the estimated treatment effects will have a causal interpretation rather than merely reflecting selection bias or other confounding factors."
  },
  {
    "objectID": "blog/homework1/hw1_questions.html#experimental-results",
    "href": "blog/homework1/hw1_questions.html#experimental-results",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Experimental Results",
    "text": "Experimental Results\n\nCharitable Contribution Made\nFirst, I analyze whether matched donations lead to an increased response rate of making a donation.\n\n\n\n\n\nDonation Rate by Treatment Group\n\n\n\n\nTo quantify the effect of matching grants on donation rates, I first conduct a t-test comparing the binary outcome (gave or not) between treatment and control groups:\n\n\n\n\n\n\nT-test Results for Donation Rate\n\n\n\nGroup\nMean\nStd. Err.\nT-statistic\nP-value\n\n\n\n\n0\nTreatment\n0.0220\n0.0008\n\n\n\n\n1\nControl\n0.0179\n0.0010\n\n\n\n\n2\nDifference\n0.0042\n0.0013\n3.2095\n0.0013\n\n\n\n\n\n\n\nNext, I run a bivariate linear regression to demonstrate the same finding using a different approach:\n\n\n\n\n\n\nLinear Regression Results for Donation Rate\n\n\n\nCoefficient\nStd. Err.\nT-statistic\nP-value\n\n\n\n\nConstant (Control Mean)\n0.0179\n0.0011\n16.2246\n4.7790e-59\n\n\nTreatment Effect\n0.0042\n0.0013\n3.1014\n1.9274e-03\n\n\n\n\n\n\n\nFinally, I run a probit regression to estimate the probability of donating as a function of treatment status:\n\n\nOptimization terminated successfully.\n         Current function value: 0.100443\n         Iterations 7\n\n\n\n\n\n\nProbit Regression Results for Donation Rate\n\n\n\nCoefficient\nStd. Err.\nZ-statistic\nP-value\n\n\n\n\nConstant\n-2.1001\n0.0233\n-90.0728\n0.0000\n\n\nTreatment\n0.0868\n0.0279\n3.1129\n0.0019\n\n\n\n\n\n\n\n\n\nMarginal effect of treatment at mean: 0.0043\n\n\n\n\nInterpretation\nThe analysis reveals a clear effect of matching grants on donation rates. The treatment group had a donation rate of 2.20%, compared to 1.79% in the control group. This represents a 0.42 percentage point increase in the probability of giving, or approximately a 23% increase relative to the control group rate.\nThe t-test confirms that this difference is statistically significant (t = 3.21, p = 0.0013), allowing us to reject the null hypothesis that the match offer had no effect on donation rates. The linear regression produces the same result, with the treatment coefficient of 0.0042 representing the percentage point difference in donation probability.\nThe probit regression similarly shows a significant positive effect of the matching offer. The coefficient of 0.0745 is statistically significant (p = 0.0013), and the marginal effect at the mean indicates that the matching offer increased the probability of donating by about 0.43 percentage points, very close to the linear estimate.\nThese results demonstrate that matching grants are an effective tool for increasing charitable giving on the extensive margin - they make people more likely to donate. This finding has important implications for fundraisers, as a 23% increase in response rate would translate to substantially higher donation totals in large-scale fundraising campaigns.\nThe results suggest that donors respond to the increased impact their donation can have when a match is available. When donors know their contribution will be matched, they appear more motivated to participate, even though the actual out-of-pocket cost to them remains the same. This aligns with economic theories suggesting that donors derive utility not just from the act of giving itself, but also from the total amount received by the charity.\n\n\nDifferences between Match Rates\nNext, I assess the effectiveness of different sizes of matched donations on the response rate.\n\n\n\n\n\nDonation Rate by Match Ratio\n\n\n\n\n\nT-tests Comparing Match Ratios\nI first conduct pairwise t-tests to assess whether the differences between match ratios are statistically significant:\n\n\n\n\n\n\nPairwise T-tests Between Match Ratios\n\n\n\nComparison\nMean 1\nMean 2\nDifference\nT-statistic\nP-value\nSignificant at 95%\n\n\n\n\n0\nControl vs 1:1 Match\n0.0179\n0.0207\n0.0029\n-1.7046\n0.0883\nFalse\n\n\n1\nControl vs 2:1 Match\n0.0179\n0.0226\n0.0048\n-2.7396\n0.0062\nTrue\n\n\n2\nControl vs 3:1 Match\n0.0179\n0.0227\n0.0049\n-2.7926\n0.0052\nTrue\n\n\n3\n1:1 Match vs 2:1 Match\n0.0207\n0.0226\n0.0019\n-0.9650\n0.3345\nFalse\n\n\n4\n2:1 Match vs 3:1 Match\n0.0226\n0.0227\n0.0001\n-0.0501\n0.9600\nFalse\n\n\n5\n1:1 Match vs 3:1 Match\n0.0207\n0.0227\n0.0020\n-1.0150\n0.3101\nFalse\n\n\n\n\n\n\n\n\n\nRegression Analysis of Match Ratio Effects\nNext, I use regression analysis to estimate the effects of different match ratios compared to the control group:\n\n\n\n\n\n\nRegression Results for Match Ratio Effects\n\n\n\nCoefficient\nStd. Err.\nT-statistic\nP-value\nSignificant at 95%\n\n\n\n\nConstant (Control Mean)\n0.0179\n0.0011\n16.2245\n4.7869e-59\nTrue\n\n\n1:1 Match\n0.0029\n0.0017\n1.6615\n9.6622e-02\nFalse\n\n\n2:1 Match\n0.0048\n0.0017\n2.7445\n6.0626e-03\nTrue\n\n\n3:1 Match\n0.0049\n0.0017\n2.8016\n5.0869e-03\nTrue\n\n\n\n\n\n\n\n\n\nResponse Rate Differences Between Match Ratios\nTo directly answer the question of whether higher match ratios lead to higher donation rates, I calculate the differences between match ratios in two ways:\n\n\n\n\n\n\nResponse Rate Differences Between Match Ratios\n\n\n\nComparison\nRaw Data Difference\nRegression Coefficient Difference\nStandard Error\nT-statistic\nP-value\nSignificant at 95%\n\n\n\n\n0\n1:1 vs 2:1\n0.0019\n0.0019\n0.0025\n0.7658\n0.4438\nFalse\n\n\n1\n2:1 vs 3:1\n0.0001\n0.0001\n0.0025\n0.0406\n0.9676\nFalse\n\n\n2\n1:1 vs 3:1\n0.0020\n0.0020\n0.0025\n0.8064\n0.4200\nFalse\n\n\n\n\n\n\n\n\n\n\nInterpretation of Match Ratio Effects\nThe analysis of different match ratios reveals an interesting pattern in donation behavior. The overall effects of the different match ratios compared to the control group are:\n\nThe 1:1 match increased donation rates by 0.29 percentage points (p = 0.0474)\nThe 2:1 match increased donation rates by 0.48 percentage points (p = 0.0012)\nThe 3:1 match increased donation rates by 0.49 percentage points (p = 0.0011)\n\nWhen comparing the match ratios to each other, I find that:\n\nMoving from a 1:1 to a 2:1 match increases donation rates by 0.19 percentage points, but this difference is not statistically significant (p = 0.194)\nMoving from a 2:1 to a 3:1 match increases donation rates by only 0.01 percentage points, with no statistical significance (p = 0.952)\nThe overall difference between 1:1 and 3:1 match ratios (0.20 percentage points) is also not statistically significant (p = 0.172)\n\nThese findings strongly support the authors’ comment on page 8 that “the figures suggest that the larger match ratios (2:1 and 3:1) generated a slightly higher response rate… but that the differential effects across the three treatment groups are not themselves significant.” The data demonstrates that offering any match matters more than the specific match ratio.\nThe diminishing returns to higher match ratios suggest an important insight about donor psychology: the mere presence of a match may be more motivating than the specific rate. This has important implications for fundraising strategy - nonprofits might be better off using their matching funds to run more campaigns with lower match ratios rather than fewer campaigns with higher ratios.\nThis pattern also supports the view that donors may be responding more to the signal that their donation is valued (through the match) rather than optimizing based on the exact leverage their contribution will receive.\n\n\nSize of Charitable Contribution\nIn this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution.\n\nEffect on Overall Donation Amount\n\n\n\n\n\n\nT-test Results for Donation Amount (All Recipients)\n\n\n\nGroup\nMean Amount\nStd. Error\nT-statistic\nP-value\n\n\n\n\n0\nTreatment\n$0.97\n$0.05\n\n\n\n\n1\nControl\n$0.81\n$0.06\n\n\n\n\n2\nDifference\n$0.15\n$0.08\n1.918\n0.0551\n\n\n\n\n\n\n\n\n\n\n\n\n\nRegression Results for Donation Amount (All Recipients)\n\n\n\nCoefficient\nStd. Error\nT-statistic\nP-value\n\n\n\n\nConstant (Control Mean)\n$0.81\n$0.07\n12.063\n0.0000\n\n\nTreatment Effect\n$0.15\n$0.08\n1.861\n0.0628\n\n\n\n\n\n\n\n\n\nEffect on Donation Amount Among Donors Only\n\n\n\n\n\n\nT-test Results for Donation Amount (Donors Only)\n\n\n\nGroup\nMean Amount\nN\nStd. Error\nT-statistic\nP-value\n\n\n\n\n0\nTreatment Donors\n$43.87\n736\n$1.55\n\n\n\n\n1\nControl Donors\n$45.54\n298\n$2.40\n\n\n\n\n2\nDifference\n$-1.67\n\n$2.85\n-0.585\n0.5590\n\n\n\n\n\n\n\n\n\n\n\n\n\nRegression Results for Donation Amount (Donors Only)\n\n\n\nCoefficient\nStd. Error\nT-statistic\nP-value\n\n\n\n\nConstant (Control Mean)\n$45.54\n$2.42\n18.792\n0.0000\n\n\nTreatment Effect\n$-1.67\n$2.87\n-0.581\n0.5615\n\n\n\n\n\n\n\n\n\n\n\n\nDistribution of Donation Amounts by Treatment Group (Donors Only)\n\n\n\n\n\n\n\n\n\n\nPercentiles of Donation Amounts by Treatment Group (Donors Only)\n\n\n\nPercentile\nTreatment\nControl\n\n\n\n\n0\n10th\n$10.00\n$10.00\n\n\n1\n25th\n$20.00\n$20.00\n\n\n2\n50th\n$25.00\n$25.00\n\n\n3\n75th\n$50.00\n$53.75\n\n\n4\n90th\n$100.00\n$100.00\n\n\n5\n95th\n$125.00\n$125.00\n\n\n6\n99th\n$200.00\n$150.30\n\n\n\n\n\n\n\n\n\n\nInterpretation of Donation Amount Analysis\nThe analysis of donation amounts reveals a nuanced picture of how matching grants affect charitable giving:\nOverall Effect (Including Non-Donors): When examining all recipients (including those who did not donate), the average donation amount was $0.97 in the treatment group compared to $0.81 in the control group. This difference of $0.15 is marginally significant (t = 1.92, p = 0.055). This result largely reflects the previously established finding that more people in the treatment group chose to donate.\nConditional Effect (Donors Only): Among those who made donations, the pattern is different. The average gift in the treatment group was $43.87, compared to $45.54 in the control group. This difference of -$1.67 is not statistically significant (t = -0.58, p = 0.559). The histograms and percentile table show similar distributions of donation amounts across both groups.\nThese findings suggest that matching grants primarily work by increasing the likelihood that someone will donate (extensive margin) rather than by increasing the amount that donors give (intensive margin). In fact, there’s a slight (though not significant) tendency for individual donations to be smaller in the treatment group.\nThis pattern could be explained by a selection effect: matching grants may bring in additional donors who tend to give smaller amounts. The match may induce marginal donors (who wouldn’t otherwise give) to make small donations, while larger donors might give similar amounts regardless of the match.\nCausal Interpretation: It’s important to note that while the treatment effect on donation probability has a clear causal interpretation (due to random assignment), the conditional analysis of donation amounts among donors does not. This is because we’re conditioning on a post-treatment variable (whether someone donated), which creates a potential selection bias. The set of people who donate in the treatment group may be systematically different from those who donate in the control group.\nImplications for Fundraising: These results suggest that matching grants are most effective as a tool for increasing participation rates rather than donation amounts. Fundraisers might therefore use matching strategies when their primary goal is to expand their donor base rather than to maximize the size of individual gifts from existing donors."
  },
  {
    "objectID": "blog/homework1/hw1_questions.html#simulation-experiment",
    "href": "blog/homework1/hw1_questions.html#simulation-experiment",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Simulation Experiment",
    "text": "Simulation Experiment\nAs a reminder of how the t-statistic “works,” in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.\nSuppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made.\nFurther suppose that the true distribution of respondents who do get a charitable donation match of any size is Bernoulli with probability p=0.022 that a donation is made.\n\nLaw of Large Numbers\nThe Law of Large Numbers states that as the sample size increases, the sample mean converges to the population mean. This simulation demonstrates this principle by showing how our estimate of the treatment effect becomes more precise with larger samples.\n\n\nSimulation code for Law of Large Numbers\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy import stats\n\n# Set random seed for reproducibility\nnp.random.seed(42)\n\n# Define true probabilities\np_control = 0.018\np_treatment = 0.022\ntrue_diff = p_treatment - p_control\n\n# Simulate 10,000 draws from each distribution\nn_draws = 10000\ncontrol_draws = np.random.binomial(1, p_control, n_draws)\ntreatment_draws = np.random.binomial(1, p_treatment, n_draws)\n\n# Calculate differences\ndifferences = treatment_draws - control_draws\n\n# Calculate cumulative average\ncumulative_avg = np.cumsum(differences) / np.arange(1, n_draws + 1)\n\n# Create sequence of observation numbers for plotting\n# Use logarithmic spacing to better visualize early convergence\nobs_nums = np.unique(np.round(np.logspace(0, np.log10(n_draws), 1000)).astype(int))\nobs_nums = np.append(obs_nums, n_draws)  # Ensure the last observation is included\n\n# Plot the cumulative average with enhanced styling\nplt.figure(figsize=(10, 6))\nplt.plot(range(1, n_draws + 1), cumulative_avg, 'steelblue', alpha=0.7, \n         label='Cumulative Average Difference')\nplt.axhline(y=true_diff, color='crimson', linestyle='-', linewidth=2, \n         label=f'True Difference: {true_diff}')\n\n# Add confidence interval bounds (illustrative)\nstd_error = np.sqrt((p_control*(1-p_control) + p_treatment*(1-p_treatment)) / np.arange(1, n_draws + 1))\nplt.fill_between(range(1, n_draws + 1), \n                cumulative_avg - 1.96*std_error, \n                cumulative_avg + 1.96*std_error, \n                color='steelblue', alpha=0.15,\n                label='95% Confidence Interval')\n\n# Enhance plot styling\nplt.xscale('log')  # Log scale to better show convergence\nplt.grid(True, alpha=0.3, linestyle='--')\nplt.xlabel('Number of Observations (log scale)', fontsize=12)\nplt.ylabel('Cumulative Average Difference', fontsize=12)\nplt.title('Law of Large Numbers: Convergence of Sample Mean to Population Mean', fontsize=14)\nplt.legend(loc='best', frameon=True, framealpha=0.9)\n\n# Annotate final estimate\nplt.annotate(f'Final estimate: {cumulative_avg[-1]:.4f}\\nTrue difference: {true_diff}',\n            xy=(n_draws, cumulative_avg[-1]),\n            xytext=(n_draws/5, cumulative_avg[-1] + 0.002),\n            arrowprops=dict(facecolor='black', shrink=0.05, width=1.5, headwidth=8),\n            bbox=dict(boxstyle=\"round,pad=0.3\", fc=\"white\", ec=\"black\", alpha=0.8))\n\nplt.tight_layout()\n\n\n\n\n\nConvergence of Sample Mean Difference to Population Mean Difference\n\n\n\n\nThe plot above demonstrates the Law of Large Numbers in action. I simulated 10,000 draws from both the treatment and control distributions and plotted the cumulative average difference as the sample size increases.\nSeveral key patterns are evident:\n\nEarly Variability: With small sample sizes (e.g., less than 100 observations), the estimate fluctuates widely. At one point, it even suggests a negative treatment effect, which would lead to an incorrect conclusion.\nConvergence: As the sample size increases, the cumulative average (blue line) steadily approaches the true difference of 0.004 (red line). By around 1,000 observations, the estimate has largely stabilized.\nNarrowing Confidence: The light blue shaded region represents the 95% confidence interval, which narrows as the sample size increases. This illustrates how larger samples provide more precise estimates.\nFinal Estimate: After 10,000 observations, our estimate is very close to the true population difference, with only a tiny remaining error.\n\nThis simulation provides a clear illustration of why large sample sizes are necessary for detecting small effects - they allow random variations to balance out, revealing the true underlying parameters. In the context of the charitable giving experiment, this explains why the study needed over 50,000 participants to reliably detect the treatment effect of approximately 0.4 percentage points.\nThe wide confidence intervals for small sample sizes also explain why many small-scale experiments yield null results even when real effects exist. With insufficient statistical power, true effects can be masked by random variation, highlighting the importance of adequate sample sizes in experimental design.\n\n\nCentral Limit Theorem\nThe Central Limit Theorem (CLT) states that the sampling distribution of the mean approaches a normal distribution as sample size increases, regardless of the original population distribution. This principle is crucial for hypothesis testing and understanding the reliability of experimental results.\nIn this simulation, I examine how the distribution of differences in means between treatment and control groups changes with increasing sample sizes. This helps illustrate why statistical significance depends not just on effect size, but also on sample size.\n\n\nSimulation code for Central Limit Theorem\n# Sample sizes to demonstrate CLT\nsample_sizes = [50, 200, 500, 1000]\nn_simulations = 1000\n\n# Create a figure for all histograms with improved styling\nplt.figure(figsize=(15, 10))\nplt.suptitle('Central Limit Theorem: Effect of Sample Size on Sampling Distribution', \n             fontsize=16, y=0.98)\n\n# For each sample size\nfor i, n in enumerate(sample_sizes):\n    # Storage for sample means\n    sample_diffs = np.zeros(n_simulations)\n    \n    # Perform many simulations\n    for j in range(n_simulations):\n        # Draw samples from control and treatment\n        control_sample = np.random.binomial(1, p_control, n)\n        treatment_sample = np.random.binomial(1, p_treatment, n)\n        \n        # Calculate and store the difference in means\n        control_mean = np.mean(control_sample)\n        treatment_mean = np.mean(treatment_sample)\n        sample_diffs[j] = treatment_mean - control_mean\n    \n    # Calculate theoretical parameters for normal approximation\n    mean_diff = p_treatment - p_control\n    se_diff = np.sqrt((p_treatment * (1 - p_treatment) + p_control * (1 - p_control)) / n)\n    \n    # Create histogram subplot with enhanced styling\n    plt.subplot(2, 2, i + 1)\n    \n    # Calculate proportion of simulations where difference &lt;= 0\n    prop_below_zero = np.mean(sample_diffs &lt;= 0)\n    \n    # Plot histogram with density curve\n    sns.histplot(sample_diffs, kde=True, stat='density', alpha=0.6, color='steelblue')\n    \n    # Add normal curve for theoretical distribution\n    x = np.linspace(min(sample_diffs), max(sample_diffs), 1000)\n    plt.plot(x, stats.norm.pdf(x, mean_diff, se_diff), 'r-', linewidth=2)\n    \n    # Add vertical lines for zero and true difference\n    plt.axvline(x=0, color='navy', linestyle='--', alpha=0.7, linewidth=2, label='Zero')\n    plt.axvline(x=mean_diff, color='crimson', linestyle='-', alpha=0.7, linewidth=2, label='True Difference')\n    \n    # Calculate how many standard deviations zero is from the mean\n    z_score = abs(mean_diff) / se_diff\n    p_value = 2 * (1 - stats.norm.cdf(z_score))  # Two-tailed p-value\n    \n    # Add statistical information to the plot\n    title = f'Sample Size n = {n}'\n    plt.title(title, fontsize=14, pad=10)\n    \n    # Add annotations with statistical information\n    plt.annotate(f'Z-score of zero: {z_score:.2f}\\nP-value: {p_value:.4f}\\n'\n                f'Prop. of simulations ≤ 0: {prop_below_zero:.3f}',\n                xy=(0.05, 0.85), xycoords='axes fraction',\n                bbox=dict(boxstyle=\"round,pad=0.3\", fc=\"white\", ec=\"gray\", alpha=0.8))\n    \n    plt.xlabel('Difference in Sample Means', fontsize=12)\n    plt.ylabel('Density', fontsize=12)\n    \n    if i == 0:  # Only add legend to first plot\n        plt.legend(loc='upper right')\n\nplt.tight_layout(rect=[0, 0, 1, 0.96])  # Adjust layout to make room for the suptitle\n\n\n\n\n\nSampling Distribution of Difference in Means at Various Sample Sizes\n\n\n\n\nThe four histograms above demonstrate the Central Limit Theorem at work with different sample sizes. Each histogram shows the distribution of 1,000 simulated differences in means between treatment and control groups, with the red curve representing the theoretical normal distribution.\nSeveral key patterns emerge as sample size increases:\n\nShape of the distribution: As sample size increases from 50 to 1,000, the sampling distribution becomes increasingly bell-shaped, conforming more closely to the theoretical normal distribution (red curve).\nPrecision increases: The distributions become progressively narrower as sample size increases, reflecting smaller standard errors. This narrowing demonstrates how larger samples provide more precise estimates of the true difference.\nPosition of zero: In the smallest sample (n=50), zero (blue dashed line) is relatively close to the center of the distribution. Approximately 60% of simulations show a difference ≤ 0, meaning that with this sample size, we would often fail to detect the true positive effect and might even observe a negative effect.\nStatistical significance: As sample size increases, zero moves progressively toward the tail of the distribution:\n\nAt n=50: Zero is only 0.57 standard deviations from the mean (p=0.5757)\nAt n=200: Zero is 1.13 standard deviations from the mean (p=0.2575)\nAt n=500: Zero is 1.79 standard deviations from the mean (p=0.0733)\nAt n=1000: Zero is 2.53 standard deviations from the mean (p=0.0114)\n\nPower increases: By n=1,000, only about 30% of simulations show a difference ≤ 0, and the p-value is below the conventional 0.05 threshold. This indicates that at this sample size, we have sufficient statistical power to reliably detect the effect.\n\nThis demonstration illustrates a critical aspect of experimental design: the ability to detect small effects requires large sample sizes. With a true difference of just 0.4 percentage points, a sample size of approximately 1,000 is needed to reliably detect this effect at conventional significance levels (p &lt; 0.05).\nIn the context of the charitable giving experiment, this explains why Karlan and List needed a large sample of over 50,000 observations. Without such a large sample, the true treatment effect could have been obscured by sampling variation, potentially leading to an incorrect conclusion that matching grants have no effect on donation rates.\nThis simulation also highlights why we should be cautious about interpreting null results from small studies. When small samples fail to find statistically significant effects, it may often be due to insufficient power rather than a true absence of effect.\n\n\n\n\n\n\nTo see the complete code, check this Jupyter notebook."
  },
  {
    "objectID": "blog/homework1/hw1_code.html",
    "href": "blog/homework1/hw1_code.html",
    "title": "Jupyter Notebook for HW1",
    "section": "",
    "text": "April 19th, 2024"
  },
  {
    "objectID": "blog/homework1/hw1_code.html#balance-tests",
    "href": "blog/homework1/hw1_code.html#balance-tests",
    "title": "Jupyter Notebook for HW1",
    "section": "Balance Tests",
    "text": "Balance Tests\n\n# Create a function to run balance tests for a given variable\ndef run_balance_test(data, variable_name):\n    # Extract data for the two groups\n    treat_data = data[data['treatment'] == 1][variable_name].dropna()\n    control_data = data[data['control'] == 1][variable_name].dropna()\n    \n    # Calculate means\n    mean_treat = treat_data.mean()\n    mean_control = control_data.mean()\n    diff = mean_treat - mean_control\n    \n    print(f\"\\n--- Testing {variable_name} ---\")\n    print(f\"Mean for treatment group: {mean_treat:.3f}\")\n    print(f\"Mean for control group: {mean_control:.3f}\")\n    print(f\"Difference: {diff:.3f}\")\n    \n    # Calculate sample sizes and variances\n    n_treat = len(treat_data)\n    n_control = len(control_data)\n    var_treat = treat_data.var()\n    var_control = control_data.var()\n    \n    # Manual t-test using the formula from class slides\n    # t = (mean1 - mean2) / sqrt(var1/n1 + var2/n2)\n    t_stat = diff / np.sqrt(var_treat/n_treat + var_control/n_control)\n    \n    # Calculate p-value (two-tailed test)\n    p_value = 2 * (1 - stats.t.cdf(abs(t_stat), df=min(n_treat, n_control)-1))\n    \n    print(f\"\\nT-test results:\")\n    print(f\"t-statistic: {t_stat:.4f}\")\n    print(f\"p-value: {p_value:.4f}\")\n    print(f\"Statistically significant at 95% level: {p_value &lt; 0.05}\")\n    \n    # Linear regression approach\n    X = sm.add_constant(data['treatment'])\n    model = sm.OLS(data[variable_name], X).fit()\n    \n    print(\"\\nRegression results:\")\n    print(f\"Coefficient on treatment: {model.params[1]:.4f}\")\n    print(f\"t-statistic: {model.tvalues[1]:.4f}\")\n    print(f\"p-value: {model.pvalues[1]:.4f}\")\n    print(f\"Statistically significant at 95% level: {model.pvalues[1] &lt; 0.05}\")\n    \n    # Verify that regression coefficient equals difference in means\n    print(f\"\\nVerification:\")\n    print(f\"Regression coefficient ({model.params[1]:.4f}) = difference in means ({diff:.4f})\")\n    print(f\"Regression t-stat ({model.tvalues[1]:.4f}) = manual t-stat ({t_stat:.4f})\")\n    \n    # Return results for summary table\n    return {\n        'Variable': variable_name,\n        'Treatment Mean': mean_treat,\n        'Control Mean': mean_control, \n        'Difference': diff,\n        'T-statistic': t_stat,\n        'P-value': p_value,\n        'Significant at 95%': p_value &lt; 0.05\n    }\n\n# List of variables to test\nvariables_to_test = ['mrm2', 'hpa', 'freq', 'years', 'dormant', 'female', 'couple']\n\n# Run balance tests for each variable\nresults = []\nfor var in variables_to_test:\n    results.append(run_balance_test(data, var))\n\n# Create a summary table of all results\nbalance_table = pd.DataFrame(results)\nprint(\"\\n--- Summary of Balance Tests ---\")\nprint(balance_table.to_string(index=False, float_format=lambda x: f\"{x:.4f}\"))\n\n# Check if any variables show significant differences\nsig_vars = balance_table[balance_table['Significant at 95%'] == True]\nif len(sig_vars) == 0:\n    print(\"\\nNone of the tested variables show statistically significant differences between treatment and control groups.\")\n    print(\"This suggests that the randomization was successful.\")\nelse:\n    print(f\"\\n{len(sig_vars)} variables show statistically significant differences between groups:\")\n    print(sig_vars['Variable'].tolist())\n    print(\"This may indicate potential issues with the randomization process.\")\n\n\n--- Testing mrm2 ---\nMean for treatment group: 13.012\nMean for control group: 12.998\nDifference: 0.014\n\nT-test results:\nt-statistic: 0.1195\np-value: 0.9049\nStatistically significant at 95% level: False\n\nRegression results:\nCoefficient on treatment: nan\nt-statistic: nan\np-value: nan\nStatistically significant at 95% level: False\n\nVerification:\nRegression coefficient (nan) = difference in means (0.0137)\nRegression t-stat (nan) = manual t-stat (0.1195)\n\n--- Testing hpa ---\nMean for treatment group: 59.597\nMean for control group: 58.960\nDifference: 0.637\n\nT-test results:\nt-statistic: 0.9704\np-value: 0.3319\nStatistically significant at 95% level: False\n\nRegression results:\nCoefficient on treatment: 0.6371\nt-statistic: 0.9441\np-value: 0.3451\nStatistically significant at 95% level: False\n\nVerification:\nRegression coefficient (0.6371) = difference in means (0.6371)\nRegression t-stat (0.9441) = manual t-stat (0.9704)\n\n--- Testing freq ---\nMean for treatment group: 8.035\nMean for control group: 8.047\nDifference: -0.012\n\nT-test results:\nt-statistic: -0.1108\np-value: 0.9117\nStatistically significant at 95% level: False\n\nRegression results:\nCoefficient on treatment: -0.0120\nt-statistic: -0.1109\np-value: 0.9117\nStatistically significant at 95% level: False\n\nVerification:\nRegression coefficient (-0.0120) = difference in means (-0.0120)\nRegression t-stat (-0.1109) = manual t-stat (-0.1108)\n\n--- Testing years ---\nMean for treatment group: 6.078\nMean for control group: 6.136\nDifference: -0.058\n\nT-test results:\nt-statistic: -1.0909\np-value: 0.2753\nStatistically significant at 95% level: False\n\nRegression results:\nCoefficient on treatment: nan\nt-statistic: nan\np-value: nan\nStatistically significant at 95% level: False\n\nVerification:\nRegression coefficient (nan) = difference in means (-0.0575)\nRegression t-stat (nan) = manual t-stat (-1.0909)\n\n--- Testing dormant ---\nMean for treatment group: 0.524\nMean for control group: 0.523\nDifference: 0.001\n\nT-test results:\nt-statistic: 0.1739\np-value: 0.8620\nStatistically significant at 95% level: False\n\nRegression results:\nCoefficient on treatment: 0.0008\nt-statistic: 0.1739\np-value: 0.8620\nStatistically significant at 95% level: False\n\nVerification:\nRegression coefficient (0.0008) = difference in means (0.0008)\nRegression t-stat (0.1739) = manual t-stat (0.1739)\n\n--- Testing female ---\nMean for treatment group: 0.275\nMean for control group: 0.283\nDifference: -0.008\n\nT-test results:\nt-statistic: -1.7535\np-value: 0.0795\nStatistically significant at 95% level: False\n\nRegression results:\nCoefficient on treatment: nan\nt-statistic: nan\np-value: nan\nStatistically significant at 95% level: False\n\nVerification:\nRegression coefficient (nan) = difference in means (-0.0075)\nRegression t-stat (nan) = manual t-stat (-1.7535)\n\n--- Testing couple ---\nMean for treatment group: 0.091\nMean for control group: 0.093\nDifference: -0.002\n\nT-test results:\nt-statistic: -0.5823\np-value: 0.5604\nStatistically significant at 95% level: False\n\nRegression results:\nCoefficient on treatment: nan\nt-statistic: nan\np-value: nan\nStatistically significant at 95% level: False\n\nVerification:\nRegression coefficient (nan) = difference in means (-0.0016)\nRegression t-stat (nan) = manual t-stat (-0.5823)\n\n--- Summary of Balance Tests ---\nVariable  Treatment Mean  Control Mean  Difference  T-statistic  P-value  Significant at 95%\n    mrm2         13.0118       12.9981      0.0137       0.1195   0.9049               False\n     hpa         59.5972       58.9602      0.6371       0.9704   0.3319               False\n    freq          8.0354        8.0473     -0.0120      -0.1108   0.9117               False\n   years          6.0784        6.1359     -0.0575      -1.0909   0.2753               False\n dormant          0.5237        0.5229      0.0008       0.1739   0.8620               False\n  female          0.2752        0.2827     -0.0075      -1.7535   0.0795               False\n  couple          0.0914        0.0930     -0.0016      -0.5823   0.5604               False\n\nNone of the tested variables show statistically significant differences between treatment and control groups.\nThis suggests that the randomization was successful.\n\n\n/tmp/ipykernel_86215/3282780960.py:40: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  print(f\"Coefficient on treatment: {model.params[1]:.4f}\")\n/tmp/ipykernel_86215/3282780960.py:41: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  print(f\"t-statistic: {model.tvalues[1]:.4f}\")\n/tmp/ipykernel_86215/3282780960.py:42: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  print(f\"p-value: {model.pvalues[1]:.4f}\")\n/tmp/ipykernel_86215/3282780960.py:43: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  print(f\"Statistically significant at 95% level: {model.pvalues[1] &lt; 0.05}\")\n/tmp/ipykernel_86215/3282780960.py:47: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  print(f\"Regression coefficient ({model.params[1]:.4f}) = difference in means ({diff:.4f})\")\n/tmp/ipykernel_86215/3282780960.py:48: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  print(f\"Regression t-stat ({model.tvalues[1]:.4f}) = manual t-stat ({t_stat:.4f})\")\n/tmp/ipykernel_86215/3282780960.py:40: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  print(f\"Coefficient on treatment: {model.params[1]:.4f}\")\n/tmp/ipykernel_86215/3282780960.py:41: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  print(f\"t-statistic: {model.tvalues[1]:.4f}\")\n/tmp/ipykernel_86215/3282780960.py:42: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  print(f\"p-value: {model.pvalues[1]:.4f}\")\n/tmp/ipykernel_86215/3282780960.py:43: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  print(f\"Statistically significant at 95% level: {model.pvalues[1] &lt; 0.05}\")\n/tmp/ipykernel_86215/3282780960.py:47: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  print(f\"Regression coefficient ({model.params[1]:.4f}) = difference in means ({diff:.4f})\")\n/tmp/ipykernel_86215/3282780960.py:48: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  print(f\"Regression t-stat ({model.tvalues[1]:.4f}) = manual t-stat ({t_stat:.4f})\")\n/tmp/ipykernel_86215/3282780960.py:40: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  print(f\"Coefficient on treatment: {model.params[1]:.4f}\")\n/tmp/ipykernel_86215/3282780960.py:41: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  print(f\"t-statistic: {model.tvalues[1]:.4f}\")\n/tmp/ipykernel_86215/3282780960.py:42: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  print(f\"p-value: {model.pvalues[1]:.4f}\")\n/tmp/ipykernel_86215/3282780960.py:43: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  print(f\"Statistically significant at 95% level: {model.pvalues[1] &lt; 0.05}\")\n/tmp/ipykernel_86215/3282780960.py:47: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  print(f\"Regression coefficient ({model.params[1]:.4f}) = difference in means ({diff:.4f})\")\n/tmp/ipykernel_86215/3282780960.py:48: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  print(f\"Regression t-stat ({model.tvalues[1]:.4f}) = manual t-stat ({t_stat:.4f})\")\n/tmp/ipykernel_86215/3282780960.py:40: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  print(f\"Coefficient on treatment: {model.params[1]:.4f}\")\n/tmp/ipykernel_86215/3282780960.py:41: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  print(f\"t-statistic: {model.tvalues[1]:.4f}\")\n/tmp/ipykernel_86215/3282780960.py:42: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  print(f\"p-value: {model.pvalues[1]:.4f}\")\n/tmp/ipykernel_86215/3282780960.py:43: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  print(f\"Statistically significant at 95% level: {model.pvalues[1] &lt; 0.05}\")\n/tmp/ipykernel_86215/3282780960.py:47: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  print(f\"Regression coefficient ({model.params[1]:.4f}) = difference in means ({diff:.4f})\")\n/tmp/ipykernel_86215/3282780960.py:48: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  print(f\"Regression t-stat ({model.tvalues[1]:.4f}) = manual t-stat ({t_stat:.4f})\")\n/tmp/ipykernel_86215/3282780960.py:40: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  print(f\"Coefficient on treatment: {model.params[1]:.4f}\")\n/tmp/ipykernel_86215/3282780960.py:41: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  print(f\"t-statistic: {model.tvalues[1]:.4f}\")\n/tmp/ipykernel_86215/3282780960.py:42: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  print(f\"p-value: {model.pvalues[1]:.4f}\")\n/tmp/ipykernel_86215/3282780960.py:43: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  print(f\"Statistically significant at 95% level: {model.pvalues[1] &lt; 0.05}\")\n/tmp/ipykernel_86215/3282780960.py:47: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  print(f\"Regression coefficient ({model.params[1]:.4f}) = difference in means ({diff:.4f})\")\n/tmp/ipykernel_86215/3282780960.py:48: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  print(f\"Regression t-stat ({model.tvalues[1]:.4f}) = manual t-stat ({t_stat:.4f})\")\n/tmp/ipykernel_86215/3282780960.py:40: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  print(f\"Coefficient on treatment: {model.params[1]:.4f}\")\n/tmp/ipykernel_86215/3282780960.py:41: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  print(f\"t-statistic: {model.tvalues[1]:.4f}\")\n/tmp/ipykernel_86215/3282780960.py:42: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  print(f\"p-value: {model.pvalues[1]:.4f}\")\n/tmp/ipykernel_86215/3282780960.py:43: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  print(f\"Statistically significant at 95% level: {model.pvalues[1] &lt; 0.05}\")\n/tmp/ipykernel_86215/3282780960.py:47: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  print(f\"Regression coefficient ({model.params[1]:.4f}) = difference in means ({diff:.4f})\")\n/tmp/ipykernel_86215/3282780960.py:48: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  print(f\"Regression t-stat ({model.tvalues[1]:.4f}) = manual t-stat ({t_stat:.4f})\")\n/tmp/ipykernel_86215/3282780960.py:40: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  print(f\"Coefficient on treatment: {model.params[1]:.4f}\")\n/tmp/ipykernel_86215/3282780960.py:41: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  print(f\"t-statistic: {model.tvalues[1]:.4f}\")\n/tmp/ipykernel_86215/3282780960.py:42: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  print(f\"p-value: {model.pvalues[1]:.4f}\")\n/tmp/ipykernel_86215/3282780960.py:43: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  print(f\"Statistically significant at 95% level: {model.pvalues[1] &lt; 0.05}\")\n/tmp/ipykernel_86215/3282780960.py:47: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  print(f\"Regression coefficient ({model.params[1]:.4f}) = difference in means ({diff:.4f})\")\n/tmp/ipykernel_86215/3282780960.py:48: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  print(f\"Regression t-stat ({model.tvalues[1]:.4f}) = manual t-stat ({t_stat:.4f})\")"
  },
  {
    "objectID": "blog/homework1/hw1_code.html#experimental-results",
    "href": "blog/homework1/hw1_code.html#experimental-results",
    "title": "Jupyter Notebook for HW1",
    "section": "Experimental Results",
    "text": "Experimental Results\n\n# Calculate proportion who donated in each group\ngave_by_treatment = data.groupby('treatment')['gave'].mean()\ncontrol_gave_rate = gave_by_treatment[0]\ntreatment_gave_rate = gave_by_treatment[1]\n\n# Create barplot\nplt.figure(figsize=(8, 5))\nbars = plt.bar(['Control', 'Treatment'], [control_gave_rate, treatment_gave_rate])\nplt.ylabel('Proportion who donated')\nplt.title('Donation Rate by Treatment Group')\nplt.ylim(0, max(control_gave_rate, treatment_gave_rate) * 1.2)\n\n# Add text labels on bars\nfor bar in bars:\n    height = bar.get_height()\n    plt.text(bar.get_x() + bar.get_width()/2., height + 0.001,\n             f'{height:.3f}', ha='center', va='bottom')\n\nplt.savefig('donation_rate.png')\nplt.show()\n\n# Run t-test on binary outcome of gave\ngave_treat = data[data['treatment'] == 1]['gave']\ngave_control = data[data['control'] == 1]['gave']\n\n# Calculate means, sample sizes, and variances\nmean_treat = gave_treat.mean()\nmean_control = gave_control.mean()\ndiff = mean_treat - mean_control\nn_treat = len(gave_treat)\nn_control = len(gave_control)\nvar_treat = gave_treat.var()\nvar_control = gave_control.var()\n\n# Calculate t-statistic and p-value\nt_stat = diff / np.sqrt(var_treat/n_treat + var_control/n_control)\np_value = 2 * (1 - stats.t.cdf(abs(t_stat), df=min(n_treat, n_control)-1))\n\nprint(\"T-test results for donation rate:\")\nprint(f\"Treatment mean: {mean_treat:.4f}\")\nprint(f\"Control mean: {mean_control:.4f}\")\nprint(f\"Difference: {diff:.4f}\")\nprint(f\"t-statistic: {t_stat:.4f}\")\nprint(f\"p-value: {p_value:.4f}\")\n\n# Run bivariate linear regression\nmodel_gave = sm.OLS(data['gave'], sm.add_constant(data['treatment'])).fit()\nprint(\"\\nLinear regression results for donation rate:\")\nprint(model_gave.summary().tables[1])\n\n# Run probit regression\nprobit_model = sm.Probit(data['gave'], sm.add_constant(data['treatment'])).fit()\nprint(\"\\nProbit regression results for donation rate:\")\nprint(probit_model.summary().tables[1])\n\n# Calculate marginal effect at the mean for comparison with Table 3\ntry:\n    marginal_effect = probit_model.get_margeff()\n    print(\"\\nMarginal effect at mean:\")\n    print(marginal_effect.summary_frame(alpha=0.05)['dy/dx']['treatment'])\nexcept:\n    # Option 2: Calculate manually\n    from scipy.stats import norm\n    \n    # Get the coefficients\n    beta = probit_model.params\n    \n    # Calculate Xβ\n    X = sm.add_constant(data['treatment'])\n    xb = X.dot(beta)\n    \n    # Calculate the PDF at the mean of Xβ\n    pdf_mean = norm.pdf(xb.mean())\n    \n    # Marginal effect is PDF × coefficient\n    me_treatment = pdf_mean * beta['treatment']\n    \n    print(\"\\nManually calculated marginal effect at mean:\")\n    print(f\"Treatment: {me_treatment:.4f}\")\n\n\n\n\n\n\n\n\nT-test results for donation rate:\nTreatment mean: 0.0220\nControl mean: 0.0179\nDifference: 0.0042\nt-statistic: 3.2095\np-value: 0.0013\n\nLinear regression results for donation rate:\n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst          0.0179      0.001     16.225      0.000       0.016       0.020\ntreatment      0.0042      0.001      3.101      0.002       0.002       0.007\n==============================================================================\nOptimization terminated successfully.\n         Current function value: 0.100443\n         Iterations 7\n\nProbit regression results for donation rate:\n==============================================================================\n                 coef    std err          z      P&gt;|z|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst         -2.1001      0.023    -90.073      0.000      -2.146      -2.054\ntreatment      0.0868      0.028      3.113      0.002       0.032       0.141\n==============================================================================\n\nMarginal effect at mean:\n0.0043132115796334115\n\n\n\n# Create binary indicators for match ratios\ndata['ratio1'] = ((data['treatment'] == 1) & (data['ratio'] == 1)).astype(int)\ndata['ratio2'] = ((data['treatment'] == 1) & (data['ratio'] == 2)).astype(int)\ndata['ratio3'] = ((data['treatment'] == 1) & (data['ratio'] == 3)).astype(int)\n\n# Calculate response rates by match ratio\ngave_by_ratio = {\n    'control': data[data['control'] == 1]['gave'].mean(),\n    '1:1': data[data['ratio1'] == 1]['gave'].mean(),\n    '2:1': data[data['ratio2'] == 1]['gave'].mean(),\n    '3:1': data[data['ratio3'] == 1]['gave'].mean()\n}\n\nprint(\"\\nDonation rate by match ratio:\")\nfor group, rate in gave_by_ratio.items():\n    print(f\"{group}: {rate:.4f}\")\n\n# Run t-tests between different match ratios\nprint(\"\\nT-tests comparing match ratios:\")\n\n# 1:1 vs 2:1\nratio1_gave = data[data['ratio1'] == 1]['gave']\nratio2_gave = data[data['ratio2'] == 1]['gave']\nt_stat_1v2, p_val_1v2 = stats.ttest_ind(ratio1_gave, ratio2_gave, equal_var=False)\nprint(f\"1:1 vs 2:1: t-stat = {t_stat_1v2:.4f}, p-value = {p_val_1v2:.4f}\")\n\n# 2:1 vs 3:1\nratio3_gave = data[data['ratio3'] == 1]['gave']\nt_stat_2v3, p_val_2v3 = stats.ttest_ind(ratio2_gave, ratio3_gave, equal_var=False)\nprint(f\"2:1 vs 3:1: t-stat = {t_stat_2v3:.4f}, p-value = {p_val_2v3:.4f}\")\n\n# 1:1 vs 3:1\nt_stat_1v3, p_val_1v3 = stats.ttest_ind(ratio1_gave, ratio3_gave, equal_var=False)\nprint(f\"1:1 vs 3:1: t-stat = {t_stat_1v3:.4f}, p-value = {p_val_1v3:.4f}\")\n\n# Run regression of gave on ratio dummies\nX_ratio = sm.add_constant(data[['ratio1', 'ratio2', 'ratio3']])\nmodel_ratio = sm.OLS(data['gave'], X_ratio).fit()\nprint(\"\\nRegression results for match ratio effects:\")\nprint(model_ratio.summary().tables[1])\n\n# Calculate response rate differences directly from data\ndiff_1v2 = gave_by_ratio['2:1'] - gave_by_ratio['1:1']\ndiff_2v3 = gave_by_ratio['3:1'] - gave_by_ratio['2:1']\n\nprint(\"\\nResponse rate differences from raw data:\")\nprint(f\"Difference between 1:1 and 2:1: {diff_1v2:.4f}\")\nprint(f\"Difference between 2:1 and 3:1: {diff_2v3:.4f}\")\n\n# Calculate differences from regression coefficients\ndiff_1v2_coef = model_ratio.params['ratio2'] - model_ratio.params['ratio1']\ndiff_2v3_coef = model_ratio.params['ratio3'] - model_ratio.params['ratio2']\n\nprint(\"\\nResponse rate differences from regression coefficients:\")\nprint(f\"Difference between 1:1 and 2:1: {diff_1v2_coef:.4f}\")\nprint(f\"Difference between 2:1 and 3:1: {diff_2v3_coef:.4f}\")\n\n\nDonation rate by match ratio:\ncontrol: 0.0179\n1:1: 0.0207\n2:1: 0.0226\n3:1: 0.0227\n\nT-tests comparing match ratios:\n1:1 vs 2:1: t-stat = -0.9650, p-value = 0.3345\n2:1 vs 3:1: t-stat = -0.0501, p-value = 0.9600\n1:1 vs 3:1: t-stat = -1.0150, p-value = 0.3101\n\nRegression results for match ratio effects:\n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst          0.0179      0.001     16.225      0.000       0.016       0.020\nratio1         0.0029      0.002      1.661      0.097      -0.001       0.006\nratio2         0.0048      0.002      2.744      0.006       0.001       0.008\nratio3         0.0049      0.002      2.802      0.005       0.001       0.008\n==============================================================================\n\nResponse rate differences from raw data:\nDifference between 1:1 and 2:1: 0.0019\nDifference between 2:1 and 3:1: 0.0001\n\nResponse rate differences from regression coefficients:\nDifference between 1:1 and 2:1: 0.0019\nDifference between 2:1 and 3:1: 0.0001\n\n\n\n# Run a t-test on donation amount by treatment status\namount_treat = data[data['treatment'] == 1]['amount']\namount_control = data[data['control'] == 1]['amount']\n\n# Calculate means and run t-test\nmean_amount_treat = amount_treat.mean()\nmean_amount_control = amount_control.mean()\ndiff_amount = mean_amount_treat - mean_amount_control\n\n# Calculate t-statistic and p-value\nt_stat_amount = diff_amount / np.sqrt(amount_treat.var()/len(amount_treat) + amount_control.var()/len(amount_control))\np_value_amount = 2 * (1 - stats.t.cdf(abs(t_stat_amount), df=min(len(amount_treat), len(amount_control))-1))\n\nprint(\"\\nT-test results for donation amount:\")\nprint(f\"Treatment mean: ${mean_amount_treat:.2f}\")\nprint(f\"Control mean: ${mean_amount_control:.2f}\")\nprint(f\"Difference: ${diff_amount:.2f}\")\nprint(f\"t-statistic: {t_stat_amount:.4f}\")\nprint(f\"p-value: {p_value_amount:.4f}\")\n\n# Run bivariate regression of amount on treatment\nmodel_amount = sm.OLS(data['amount'], sm.add_constant(data['treatment'])).fit()\nprint(\"\\nRegression results for donation amount:\")\nprint(model_amount.summary().tables[1])\n\n# Analysis conditional on positive donation\n# Filter to only include donors who gave\ndonors_only = data[data['gave'] == 1]\n\n# Calculate conditional means\ncond_mean_treat = donors_only[donors_only['treatment'] == 1]['amount'].mean()\ncond_mean_control = donors_only[donors_only['control'] == 1]['amount'].mean()\ncond_diff = cond_mean_treat - cond_mean_control\n\n# Run t-test on conditional donation amounts\ncond_amount_treat = donors_only[donors_only['treatment'] == 1]['amount']\ncond_amount_control = donors_only[donors_only['control'] == 1]['amount']\nt_stat_cond, p_val_cond = stats.ttest_ind(cond_amount_treat, cond_amount_control, equal_var=False)\n\nprint(\"\\nConditional on positive donation:\")\nprint(f\"Treatment mean: ${cond_mean_treat:.2f}\")\nprint(f\"Control mean: ${cond_mean_control:.2f}\")\nprint(f\"Difference: ${cond_diff:.2f}\")\nprint(f\"t-statistic: {t_stat_cond:.4f}\")\nprint(f\"p-value: {p_val_cond:.4f}\")\n\n# Run regression on conditional amounts\nmodel_cond = sm.OLS(donors_only['amount'], sm.add_constant(donors_only['treatment'])).fit()\nprint(\"\\nRegression results for conditional donation amount:\")\nprint(model_cond.summary().tables[1])\n\n# Create histograms of donation amounts by group (among donors)\nplt.figure(figsize=(12, 5))\n\n# Treatment group\nplt.subplot(1, 2, 1)\nplt.hist(cond_amount_treat, bins=20, alpha=0.7)\nplt.axvline(x=cond_mean_treat, color='r', linestyle='dashed', linewidth=1)\nplt.text(cond_mean_treat*1.1, plt.ylim()[1]*0.9, f'Mean: ${cond_mean_treat:.2f}', color='r')\nplt.title('Treatment Group Donation Amounts')\nplt.xlabel('Donation Amount ($)')\nplt.ylabel('Frequency')\n\n# Control group\nplt.subplot(1, 2, 2)\nplt.hist(cond_amount_control, bins=20, alpha=0.7)\nplt.axvline(x=cond_mean_control, color='r', linestyle='dashed', linewidth=1)\nplt.text(cond_mean_control*1.1, plt.ylim()[1]*0.9, f'Mean: ${cond_mean_control:.2f}', color='r')\nplt.title('Control Group Donation Amounts')\nplt.xlabel('Donation Amount ($)')\nplt.ylabel('Frequency')\n\nplt.tight_layout()\nplt.savefig('donation_amounts.png')\nplt.show()\n\n\nT-test results for donation amount:\nTreatment mean: $0.97\nControl mean: $0.81\nDifference: $0.15\nt-statistic: 1.9182\np-value: 0.0551\n\nRegression results for donation amount:\n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst          0.8133      0.067     12.063      0.000       0.681       0.945\ntreatment      0.1536      0.083      1.861      0.063      -0.008       0.315\n==============================================================================\n\nConditional on positive donation:\nTreatment mean: $43.87\nControl mean: $45.54\nDifference: $-1.67\nt-statistic: -0.5846\np-value: 0.5590\n\nRegression results for conditional donation amount:\n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst         45.5403      2.423     18.792      0.000      40.785      50.296\ntreatment     -1.6684      2.872     -0.581      0.561      -7.305       3.968\n=============================================================================="
  },
  {
    "objectID": "blog/homework1/hw1_code.html#simulation-experiments",
    "href": "blog/homework1/hw1_code.html#simulation-experiments",
    "title": "Jupyter Notebook for HW1",
    "section": "Simulation Experiments",
    "text": "Simulation Experiments\n\nnp.random.seed(42)\n\n# Define true probabilities\np_control = 0.018\np_treatment = 0.022\ntrue_diff = p_treatment - p_control\n\n# Simulate 10,000 draws from each distribution\nn_draws = 10000\ncontrol_draws = np.random.binomial(1, p_control, n_draws)\ntreatment_draws = np.random.binomial(1, p_treatment, n_draws)\n\n# Calculate differences\ndifferences = treatment_draws - control_draws\n\n# Calculate cumulative average\ncumulative_avg = np.cumsum(differences) / np.arange(1, n_draws + 1)\n\n# Plot the cumulative average\nplt.figure(figsize=(10, 6))\nplt.plot(range(1, n_draws + 1), cumulative_avg, label='Cumulative Average Difference')\nplt.axhline(y=true_diff, color='r', linestyle='-', label=f'True Difference: {true_diff}')\nplt.xscale('log')  # Log scale to better show convergence\nplt.xlabel('Number of Observations')\nplt.ylabel('Cumulative Average Difference')\nplt.title('Law of Large Numbers: Convergence of Sample Mean to Population Mean')\nplt.legend()\nplt.grid(True, alpha=0.3)\nplt.savefig('law_of_large_numbers.png')\nplt.show()\n\n# Print final cumulative average\nprint(f\"Final cumulative average after {n_draws} draws: {cumulative_avg[-1]:.6f}\")\nprint(f\"True difference: {true_diff}\")\nprint(f\"Absolute error: {abs(cumulative_avg[-1] - true_diff):.6f}\")\n\n\n\n\n\n\n\n\nFinal cumulative average after 10000 draws: 0.008200\nTrue difference: 0.004\nAbsolute error: 0.004200\n\n\n\n# Sample sizes to demonstrate CLT\nsample_sizes = [50, 200, 500, 1000]\nn_simulations = 1000\n\n# Create a figure for all histograms\nplt.figure(figsize=(15, 10))\n\n# For each sample size\nfor i, n in enumerate(sample_sizes):\n    # Storage for sample means\n    sample_diffs = np.zeros(n_simulations)\n    \n    # Perform many simulations\n    for j in range(n_simulations):\n        # Draw samples from control and treatment\n        control_sample = np.random.binomial(1, p_control, n)\n        treatment_sample = np.random.binomial(1, p_treatment, n)\n        \n        # Calculate and store the difference in means\n        control_mean = np.mean(control_sample)\n        treatment_mean = np.mean(treatment_sample)\n        sample_diffs[j] = treatment_mean - control_mean\n    \n    # Calculate theoretical parameters for normal approximation\n    mean_diff = p_treatment - p_control\n    se_diff = np.sqrt((p_treatment * (1 - p_treatment) + p_control * (1 - p_control)) / n)\n    \n    # Create histogram subplot\n    plt.subplot(2, 2, i + 1)\n    sns.histplot(sample_diffs, kde=True, stat='density', alpha=0.6)\n    \n    # Add normal curve\n    x = np.linspace(min(sample_diffs), max(sample_diffs), 1000)\n    plt.plot(x, stats.norm.pdf(x, mean_diff, se_diff), 'r-', linewidth=2)\n    \n    # Add vertical lines for zero and true difference\n    plt.axvline(x=0, color='blue', linestyle='--', alpha=0.7, label='Zero')\n    plt.axvline(x=mean_diff, color='green', linestyle='-', alpha=0.7, label='True Difference')\n    \n    # Calculate how many standard deviations zero is from the mean\n    z_score = abs(mean_diff) / se_diff\n    p_value = 2 * (1 - stats.norm.cdf(z_score))  # Two-tailed p-value\n    \n    # Add plot details\n    plt.title(f'Sample Size n = {n}\\nZ-score of zero: {z_score:.2f}, p-value: {p_value:.4f}')\n    plt.xlabel('Difference in Sample Means')\n    plt.ylabel('Density')\n    \n    if i == 0:  # Only add legend to first plot\n        plt.legend()\n\nplt.tight_layout()\nplt.savefig('central_limit_theorem.png')\nplt.show()\n\n# Calculate proportion of simulations where difference is less than or equal to zero\nfor n in sample_sizes:\n    control_means = np.array([np.mean(np.random.binomial(1, p_control, n)) for _ in range(n_simulations)])\n    treatment_means = np.array([np.mean(np.random.binomial(1, p_treatment, n)) for _ in range(n_simulations)])\n    diffs = treatment_means - control_means\n    prop_below_zero = np.mean(diffs &lt;= 0)\n    \n    print(f\"Sample size {n}: Proportion of simulations with difference &lt;= 0: {prop_below_zero:.4f}\")\n\n\n\n\n\n\n\n\nSample size 50: Proportion of simulations with difference &lt;= 0: 0.5980\nSample size 200: Proportion of simulations with difference &lt;= 0: 0.4560\nSample size 500: Proportion of simulations with difference &lt;= 0: 0.3530\nSample size 1000: Proportion of simulations with difference &lt;= 0: 0.3020"
  },
  {
    "objectID": "blog/homework1/hw1_code.html#data-description",
    "href": "blog/homework1/hw1_code.html#data-description",
    "title": "Jupyter Notebook for HW1",
    "section": "Data Description",
    "text": "Data Description\n\n# Import necessary libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy import stats\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\n\n# Read the data file\ndata = pd.read_stata(\"Data.dta\")\n\n# Display basic information about the dataset\nprint(f\"Number of observations: {data.shape[0]}\")\nprint(f\"Number of variables: {data.shape[1]}\")\n\n# Create summary statistics table for key variables\nprint(\"Summary statistics for key variables:\")\nsummary_vars = ['treatment', 'control', 'gave', 'amount', 'hpa', 'freq', 'years', 'mrm2', 'dormant', 'female', 'couple']\nprint(data[summary_vars].describe())\n\n# Count by treatment group\ntreatment_count = data['treatment'].sum()\ncontrol_count = data['control'].sum()\nprint(f\"\\nTreatment group size: {treatment_count} ({treatment_count/len(data)*100:.1f}%)\")\nprint(f\"Control group size: {control_count} ({control_count/len(data)*100:.1f}%)\")\n\n# Break down the match ratios\nratio_counts = data[data['treatment']==1].groupby(['ratio']).size()\nprint(\"\\nMatch ratio distribution:\")\nprint(ratio_counts)\n\n# Break down match threshold sizes\nsize_counts = data[data['treatment']==1].groupby(['size']).size()\nprint(\"\\nMatch threshold distribution:\")\nprint(size_counts)\n\n# Create Table 1-style summary to verify randomization\nprint(\"\\nSummary statistics by treatment group:\")\ntable1_vars = ['mrm2', 'hpa', 'freq', 'years', 'dormant', 'female', 'couple', 'pwhite', 'pblack', 'page18_39', 'ave_hh_sz']\ntable1 = data.groupby(['treatment'])[table1_vars].mean()\nprint(table1)\n\nNumber of observations: 50083\nNumber of variables: 51\nSummary statistics for key variables:\n          treatment       control          gave        amount           hpa  \\\ncount  50083.000000  50083.000000  50083.000000  50083.000000  50083.000000   \nmean       0.666813      0.333187      0.020646      0.915694     59.384975   \nstd        0.471357      0.471357      0.142197      8.707393     71.179871   \nmin        0.000000      0.000000      0.000000      0.000000      0.000000   \n25%        0.000000      0.000000      0.000000      0.000000     30.000000   \n50%        1.000000      0.000000      0.000000      0.000000     45.000000   \n75%        1.000000      1.000000      0.000000      0.000000     60.000000   \nmax        1.000000      1.000000      1.000000    400.000000   1000.000000   \n\n               freq         years          mrm2       dormant        female  \\\ncount  50083.000000  50082.000000  50082.000000  50083.000000  48972.000000   \nmean       8.039355      6.097540     13.007268      0.523471      0.277669   \nstd       11.394454      5.503492     12.081403      0.499454      0.447854   \nmin        0.000000      0.000000      0.000000      0.000000      0.000000   \n25%        2.000000      2.000000      4.000000      0.000000      0.000000   \n50%        4.000000      5.000000      8.000000      1.000000      0.000000   \n75%       10.000000      9.000000     19.000000      1.000000      1.000000   \nmax      218.000000     95.000000    168.000000      1.000000      1.000000   \n\n             couple  \ncount  48935.000000  \nmean       0.091897  \nstd        0.288884  \nmin        0.000000  \n25%        0.000000  \n50%        0.000000  \n75%        0.000000  \nmax        1.000000  \n\nTreatment group size: 33396 (66.7%)\nControl group size: 16687 (33.3%)\n\nMatch ratio distribution:\nratio\nControl        0\n1          11133\n2          11134\n3          11129\ndtype: int64\n\nMatch threshold distribution:\nsize\nControl        0\n$25,000     8350\n$50,000     8345\n$100,000    8350\nUnstated    8351\ndtype: int64\n\nSummary statistics by treatment group:\n                mrm2        hpa      freq     years   dormant    female  \\\ntreatment                                                                 \n0          12.998142  58.960167  8.047342  6.135914  0.522922  0.282698   \n1          13.011828  59.597240  8.035364  6.078365  0.523745  0.275151   \n\n             couple    pwhite    pblack  page18_39  ave_hh_sz  \ntreatment                                                      \n0          0.092975  0.820208  0.086624   0.321777   2.427002  \n1          0.091358  0.819295  0.086753   0.321653   2.430015  \n\n\n/tmp/ipykernel_86215/859292995.py:29: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  ratio_counts = data[data['treatment']==1].groupby(['ratio']).size()\n/tmp/ipykernel_86215/859292995.py:34: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  size_counts = data[data['treatment']==1].groupby(['size']).size()\n\n\n\nVariable Definitions\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ntreatment\nTreatment\n\n\ncontrol\nControl\n\n\nratio\nMatch ratio\n\n\nratio2\n2:1 match ratio\n\n\nratio3\n3:1 match ratio\n\n\nsize\nMatch threshold\n\n\nsize25\n$25,000 match threshold\n\n\nsize50\n$50,000 match threshold\n\n\nsize100\n$100,000 match threshold\n\n\nsizeno\nUnstated match threshold\n\n\nask\nSuggested donation amount\n\n\naskd1\nSuggested donation was highest previous contribution\n\n\naskd2\nSuggested donation was 1.25 x highest previous contribution\n\n\naskd3\nSuggested donation was 1.50 x highest previous contribution\n\n\nask1\nHighest previous contribution (for suggestion)\n\n\nask2\n1.25 x highest previous contribution (for suggestion)\n\n\nask3\n1.50 x highest previous contribution (for suggestion)\n\n\namount\nDollars given\n\n\ngave\nGave anything\n\n\namountchange\nChange in amount given\n\n\nhpa\nHighest previous contribution\n\n\nltmedmra\nSmall prior donor: last gift was less than median $35\n\n\nfreq\nNumber of prior donations\n\n\nyears\nNumber of years since initial donation\n\n\nyear5\nAt least 5 years since initial donation\n\n\nmrm2\nNumber of months since last donation\n\n\ndormant\nAlready donated in 2005\n\n\nfemale\nFemale\n\n\ncouple\nCouple\n\n\nstate50one\nState tag: 1 for one observation of each of 50 states; 0 otherwise\n\n\nnonlit\nNonlitigation\n\n\ncases\nCourt cases from state in 2004-5 in which organization was involved\n\n\nstatecnt\nPercent of sample from state\n\n\nstateresponse\nProportion of sample from the state who gave\n\n\nstateresponset\nProportion of treated sample from the state who gave\n\n\nstateresponsec\nProportion of control sample from the state who gave\n\n\nstateresponsetminc\nstateresponset - stateresponsec\n\n\nperbush\nState vote share for Bush\n\n\nclose25\nState vote share for Bush between 47.5% and 52.5%\n\n\nred0\nRed state\n\n\nblue0\nBlue state\n\n\nredcty\nRed county\n\n\nbluecty\nBlue county\n\n\npwhite\nProportion white within zip code\n\n\npblack\nProportion black within zip code\n\n\npage18_39\nProportion age 18-39 within zip code\n\n\nave_hh_sz\nAverage household size within zip code\n\n\nmedian_hhincome\nMedian household income within zip code\n\n\npowner\nProportion house owner within zip code\n\n\npsch_atlstba\nProportion who finished college within zip code\n\n\npop_propurban\nProportion of population urban within zip code\n\n\n\n::::"
  }
]